
async fn get_energy_metrics(state: Arc<ApiState>) -> Result<impl Reply, Rejection> {
    let energy_manager = state.energy_manager.lock().await;
    
    let node_ids = vec!["node-1", "node-2", "local"];
    let mut nodes = Vec::new();
    let mut average_energy_saved = 0.0;
    
    for node_id in node_ids {
        if let Some(metrics) = energy_manager.get_latest_node_metrics(node_id).await {
            let node_metrics = EnergyMetricsResponse {
                node_id: node_id.to_string(),
                current_consumption: metrics.current_consumption,
                total_savings: metrics.total_savings,
                history: metrics.history.clone(),
                forecast: metrics.forecast,
                last_updated: metrics.last_updated,
                active_connections: metrics.active_connections,
            };
            
            average_energy_saved += metrics.current_consumption;
            nodes.push(node_metrics);
        }
    }
    
    if !nodes.is_empty() {
        average_energy_saved /= nodes.len() as f64;
    }
    
    let response = NetworkEnergyResponse {
        average_energy_saved,
        node_count: nodes.len(),
        nodes,
    };
    
    Ok(warp::reply::json(&response))
}

async fn get_total_energy_saved(state: Arc<ApiState>) -> Result<impl Reply, Rejection> {
    let energy_manager = state.energy_manager.lock().await;
    let total_saved = energy_manager.get_total_energy_saved().await;
    
    Ok(warp::reply::json(&serde_json::json!({
        "energy_saved_percent": total_saved,
    })))
}

async fn get_node_status(node_id: String, state: Arc<ApiState>) -> Result<impl Reply, Rejection> {
    let energy_manager = state.energy_manager.lock().await;
    
    let node_metrics = match energy_manager.get_latest_node_metrics(&node_id).await {
        Some(metrics) => EnergyMetricsResponse {
            node_id: node_id.to_string(),
            current_consumption: metrics.current_consumption,
            total_savings: metrics.total_savings,
            history: metrics.history.clone(),
            forecast: metrics.forecast,
            last_updated: metrics.last_updated,
            active_connections: metrics.active_connections,
        },
        None => {
            return Ok(warp::reply::json(&serde_json::json!({
                "error": "Node not found",
                "node_id": node_id
            })));
        }
    };
    
    Ok(warp::reply::json(&node_metrics))
}

#[tokio::main]
async fn main() {
    env_logger::init();
    
    info!("Starting Energy API Demo");
    
    // Initialize the energy manager
    let mut energy_manager = EnergyManager::new()
        .with_sampling_interval(Duration::from_secs(15))
        .with_low_power_threshold(0.7);
    
    // Simulate some metrics
    energy_manager.record_tx_bytes(1500);
    energy_manager.record_rx_bytes(2500);
    
    info!("Capturing initial metrics");
    energy_manager.capture_metrics("node-1", 8).await;
    energy_manager.capture_metrics("node-2", 12).await;
    energy_manager.capture_metrics("local", 5).await;
    
    // Setup API state
    let api_state = Arc::new(ApiState {
        energy_manager: Arc::new(Mutex::new(energy_manager)),
    });
    
    // Create API routes
    let api_state_clone = api_state.clone();
    let api_state_filter = warp::any().map(move || api_state_clone.clone());
    
    // Endpoint: GET /api/metrics/energy
    let energy_route = warp::path!("api" / "metrics" / "energy")
        .and(warp::get())
        .and(api_state_filter.clone())
        .and_then(get_energy_metrics);
    
    // Endpoint: GET /api/metrics/energy/total
    let energy_total_route = warp::path!("api" / "metrics" / "energy" / "total")
        .and(warp::get())
        .and(api_state_filter.clone())
        .and_then(get_total_energy_saved);
    
    // Endpoint: GET /api/node/:id/status
    let node_status_route = warp::path!("api" / "node" / String / "status")
        .and(warp::get())
        .and(api_state_filter.clone())
        .and_then(get_node_status);
    
    // Combine routes
    let routes = energy_route
        .or(energy_total_route)
        .or(node_status_route);
    
    // Start metrics collection loop in background
    let energy_mgr_clone = api_state.energy_manager.clone();
    tokio::spawn(async move {
        loop {
            debug!("Updating metrics...");
            let mut em = energy_mgr_clone.lock().await;
            em.capture_metrics("node-1", 8 + (rand::random::<f32>() * 5.0) as usize).await;
            em.capture_metrics("node-2", 12 + (rand::random::<f32>() * 8.0) as usize).await;
            em.capture_metrics("local", 5 + (rand::random::<f32>() * 3.0) as usize).await;
            em.record_tx_bytes(100 + (rand::random::<u64>() % 1000));
            em.record_rx_bytes(200 + (rand::random::<u64>() % 1500));
            
            // Update every 10 seconds
            tokio::time::sleep(Duration::from_secs(10)).await;
        }
    });
    
    // Start server
    let port = 8081;
    info!("Starting energy API server on http://localhost:{}", port);
    info!("Available endpoints:");
    info!("- GET /api/metrics/energy - All node energy metrics");
    info!("- GET /api/metrics/energy/total - Total energy saved");
    info!("- GET /api/node/{{id}}/status - Specific node status (node-1, node-2, local)");
    
    warp::serve(routes).run(([0, 0, 0, 0], port)).await;
} use network::energy_manager::{EnergyManager, EnergyMetrics};
use std::time::Duration;

#[tokio::main]
async fn main() {
    // Configurar logger b√°sico
    env_logger::init();
    
    println!("Teste do M√≥dulo de Economia de Energia");
    println!("=====================================");
    
    // Criar gerenciador de energia
    let mut energy_manager = EnergyManager::new()
        .with_sampling_interval(Duration::from_secs(10))
        .with_low_power_threshold(0.7);
        
    println!("Gerenciador de energia criado com sucesso");
    
    // Simular tr√°fego de rede
    energy_manager.record_tx_bytes(1500);
    energy_manager.record_rx_bytes(2500);
    
    println!("Tr√°fego registrado: TX={} bytes, RX={} bytes", 
             energy_manager.get_tx_bytes(), 
             energy_manager.get_rx_bytes());
    
    // Capturar m√©tricas para dois n√≥s
    let node1 = "node-1";
    let node2 = "node-2";
    
    let metrics1 = energy_manager.capture_metrics(node1, 15).await;
    let metrics2 = energy_manager.capture_metrics(node2, 25).await;
    
    println!("\nM√©tricas do N√≥ 1:");
    print_metrics(&metrics1);
    
    println!("\nM√©tricas do N√≥ 2:");
    print_metrics(&metrics2);
    
    // Obter economia total
    let total_saved = energy_manager.get_total_energy_saved().await;
    println!("\nEconomia total de energia na rede: {:.2}%", total_saved);
    
    // Recuperar m√©tricas armazenadas
    let stored_metrics1 = energy_manager.get_latest_node_metrics(node1).await.unwrap();
    println!("\nM√©tricas armazenadas para o N√≥ 1:");
    print_metrics(&stored_metrics1);
    
    println!("\nTeste conclu√≠do com sucesso!");
}

fn print_metrics(metrics: &EnergyMetrics) {
    // Remove or comment out all lines that reference metrics.cpu_usage, metrics.memory_usage, metrics.network_tx_bytes, metrics.network_rx_bytes, metrics.energy_saved_percent
    // println!("  CPU: {:.2}%", metrics.cpu_usage);
    // println!("  Mem√≥ria: {:.2} MB", metrics.memory_usage);
    // println!("  Tr√°fego TX: {} bytes", metrics.network_tx_bytes);
    // println!("  Tr√°fego RX: {} bytes", metrics.network_rx_bytes);
    println!("  Conex√µes ativas: {}", metrics.active_connections);
    // println!("  Economia de energia: {:.2}%", metrics.energy_saved_percent);
} use network::energy_manager::EnergyManager;
use std::time::Duration;
use std::sync::Arc;
use warp::{Filter, Rejection, Reply};
use tokio::sync::Mutex;
use serde::Serialize;
use log::{info, debug};
use chrono;

#[derive(Debug, Clone, Serialize)]
struct EnergyMetricsResponse {
    node_id: String,
    current_consumption: f64,
    total_savings: f64,
    history: Vec<f64>,
    forecast: Option<f64>,
    last_updated: chrono::DateTime<chrono::Utc>,
    active_connections: usize,
}

#[derive(Debug, Clone, Serialize)]
struct NetworkEnergyResponse {
    average_energy_saved: f64,
    node_count: usize,
    nodes: Vec<EnergyMetricsResponse>,
}

// State wrapper
struct AppState {
    energy_manager: Arc<Mutex<EnergyManager>>,
}

// Handler functions with proper type signatures
async fn get_energy_metrics(state: Arc<AppState>) -> Result<impl Reply, Rejection> {
    let energy_manager = state.energy_manager.lock().await;
    
    // Simulate nodes
    let node_ids = vec!["node-1", "node-2", "local"];
    let mut nodes = Vec::new();
    let mut average_energy_saved = 0.0;
    
    for node_id in node_ids {
        if let Some(metrics) = energy_manager.get_latest_node_metrics(node_id).await {
            let node_metrics = EnergyMetricsResponse {
                node_id: node_id.to_string(),
                current_consumption: metrics.current_consumption,
                total_savings: metrics.total_savings,
                history: metrics.history.clone(),
                forecast: metrics.forecast,
                last_updated: metrics.last_updated,
                active_connections: metrics.active_connections,
            };
            
            average_energy_saved += metrics.current_consumption;
            nodes.push(node_metrics);
        }
    }
    
    if !nodes.is_empty() {
        average_energy_saved /= nodes.len() as f64;
    }
    
    let response = NetworkEnergyResponse {
        average_energy_saved,
        node_count: nodes.len(),
        nodes,
    };
    
    Ok(warp::reply::json(&response))
}

async fn get_total_energy_saved(state: Arc<AppState>) -> Result<impl Reply, Rejection> {
    let energy_manager = state.energy_manager.lock().await;
    let total_saved = energy_manager.get_total_energy_saved().await;
    
    Ok(warp::reply::json(&serde_json::json!({
        "energy_saved_percent": total_saved,
    })))
}

async fn get_node_status(node_id: String, state: Arc<AppState>) -> Result<impl Reply, Rejection> {
    let energy_manager = state.energy_manager.lock().await;
    
    let node_metrics = match energy_manager.get_latest_node_metrics(&node_id).await {
        Some(metrics) => EnergyMetricsResponse {
            node_id: node_id.to_string(),
            current_consumption: metrics.current_consumption,
            total_savings: metrics.total_savings,
            history: metrics.history.clone(),
            forecast: metrics.forecast,
            last_updated: metrics.last_updated,
            active_connections: metrics.active_connections,
        },
        None => {
            return Ok(warp::reply::json(&serde_json::json!({
                "error": "Node not found",
                "node_id": node_id
            })));
        }
    };
    
    Ok(warp::reply::json(&node_metrics))
}

// Filter creation helper function that properly handles type inference
fn with_state(state: Arc<AppState>) -> impl Filter<Extract = (Arc<AppState>,), Error = std::convert::Infallible> + Clone {
    warp::any().map(move || state.clone())
}

#[tokio::main]
async fn main() {
    // Initialize logger
    env_logger::init_from_env(env_logger::Env::new().default_filter_or("info"));
    
    info!("Starting Energy API Demo");
    
    // Initialize the energy manager
    let mut energy_manager = EnergyManager::new()
        .with_sampling_interval(Duration::from_secs(15))
        .with_low_power_threshold(0.7);
    
    // Simulate some metrics
    energy_manager.record_tx_bytes(1500);
    energy_manager.record_rx_bytes(2500);
    
    // Capture metrics for different nodes
    info!("Capturing initial metrics");
    energy_manager.capture_metrics("node-1", 8).await;
    energy_manager.capture_metrics("node-2", 12).await;
    energy_manager.capture_metrics("local", 5).await;
    
    // Setup API state
    let app_state = Arc::new(AppState {
        energy_manager: Arc::new(Mutex::new(energy_manager)),
    });
    
    // Route for energy metrics
    let energy_metrics_route = warp::path!("api" / "metrics" / "energy")
        .and(warp::get())
        .and(with_state(app_state.clone()))
        .and_then(get_energy_metrics);
    
    // Route for total energy saved
    let energy_total_route = warp::path!("api" / "metrics" / "energy" / "total")
        .and(warp::get())
        .and(with_state(app_state.clone()))
        .and_then(get_total_energy_saved);
    
    // Route for node status
    let node_status_route = warp::path!("api" / "node" / String / "status")
        .and(warp::get())
        .and(with_state(app_state.clone()))
        .and_then(|id, state| async move {
            get_node_status(id, state).await
        });
    
    // Combine all routes
    let routes = energy_metrics_route
        .or(energy_total_route)
        .or(node_status_route);
    
    // Start background metrics update task
    let energy_mgr_clone = app_state.energy_manager.clone();
    tokio::spawn(async move {
        loop {
            debug!("Updating metrics...");
            let mut em = energy_mgr_clone.lock().await;
            
            // Update with slightly random values to simulate changes
            let r = rand::random::<f32>();
            em.capture_metrics("node-1", 8 + (r * 5.0) as usize).await;
            em.capture_metrics("node-2", 12 + (r * 8.0) as usize).await;
            em.capture_metrics("local", 5 + (r * 3.0) as usize).await;
            em.record_tx_bytes(100 + (rand::random::<u64>() % 1000));
            em.record_rx_bytes(200 + (rand::random::<u64>() % 1500));
            
            tokio::time::sleep(Duration::from_secs(10)).await;
        }
    });
    
    // Start the server
    let port = 8081;
    info!("Starting energy API server on http://localhost:{}", port);
    info!("Available endpoints:");
    info!("- GET /api/metrics/energy - All node energy metrics");
    info!("- GET /api/metrics/energy/total - Total energy saved");
    info!("- GET /api/node/{{id}}/status - Specific node status (try: node-1, node-2, local)");
    
    warp::serve(routes).run(([0, 0, 0, 0], port)).await;
} use anyhow::Result;
use libp2p::PeerId;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use yrs::{
    Doc,
    Text,
    Transact,
    StateVector,
    Update,
    ReadTxn,
    types::text::TextRef,
    updates::decoder::Decode,
    GetString,
};

#[derive(Debug, Serialize, Deserialize)]
pub enum CrdtOperation {
    /// Atualiza√ß√£o de texto colaborativo
    TextUpdate {
        doc_id: String,
        update: Vec<u8>, // Encoded CRDT update
    },
    /// Solicita√ß√£o de sincroniza√ß√£o
    SyncRequest {
        doc_id: String,
        #[serde(with = "peer_id_serde")]
        from_peer: PeerId,
    },
    /// Resposta de sincroniza√ß√£o
    SyncResponse {
        doc_id: String,
        state: Vec<u8>, // Full state
    },
}

// M√≥dulo para serializa√ß√£o/deserializa√ß√£o personalizada de PeerId
mod peer_id_serde {
    use libp2p::PeerId;
    use serde::{Deserialize, Deserializer, Serializer};
    use std::str::FromStr;

    pub fn serialize<S>(peer_id: &PeerId, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        serializer.serialize_str(&peer_id.to_string())
    }

    pub fn deserialize<'de, D>(deserializer: D) -> Result<PeerId, D::Error>
    where
        D: Deserializer<'de>,
    {
        let s = String::deserialize(deserializer)?;
        PeerId::from_str(&s).map_err(serde::de::Error::custom)
    }
}

/// Gerenciador CRDT mant√©m documentos e sincroniza via gossipsub
pub struct CrdtManager {
    docs: HashMap<String, Doc>,
}

impl CrdtManager {
    /// Criar um novo gerenciador CRDT
    pub fn new() -> Self {
        Self {
            docs: HashMap::new(),
        }
    }
    
    /// Criar ou obter um documento existente
    pub fn get_or_create_document(&mut self, doc_id: &str) -> &Doc {
        if !self.docs.contains_key(doc_id) {
            let doc = Doc::new();
            self.docs.insert(doc_id.to_string(), doc);
        }
        self.docs.get(doc_id).unwrap()
    }
    
    /// Aplicar uma atualiza√ß√£o local a um documento
    pub fn apply_local_update<F>(&mut self, doc_id: &str, _f: F) -> Result<Vec<u8>> 
    where 
        F: FnOnce(&mut TextRef)
    {
        let doc = self.get_or_create_document(doc_id);
        
        let update = {
            let mut txn = doc.transact_mut();
            
            // Get or create the text
            let text_ref = txn.get_text("text").unwrap();
            text_ref.insert(&mut txn, 0, "your string");
            
            // Get the update
            let state_vector = StateVector::default();
            txn.encode_state_as_update_v1(&state_vector).to_vec()
        };
        
        Ok(update)
    }
    
    /// Aplicar uma atualiza√ß√£o remota a um documento
    pub fn apply_remote_update(&mut self, doc_id: &str, update: &[u8]) -> Result<()> {
        let doc = self.get_or_create_document(doc_id);
        
        let mut txn = doc.transact_mut();
        txn.apply_update(Update::decode_v1(update)?);
        
        Ok(())
    }
    
    /// Solicitar sincroniza√ß√£o completa
    pub fn request_sync(&mut self, _doc_id: &str) -> Result<()> {
        // Implementation needed
        Ok(())
    }
    
    /// Processar mensagem recebida
    pub fn process_message(&mut self, _from_peer: PeerId, message: &[u8]) -> Result<()> {
        // Here we would process incoming CRDT messages
        // For now just apply the update directly
        self.apply_remote_update("default", message)
    }
    
    pub fn get_text(&self, doc_id: &str) -> Option<String> {
        self.docs.get(doc_id).map(|doc| {
            let txn = doc.transact();
            let text = txn.get_text("text");
            text.map(|t| t.get_string(&txn)).unwrap_or_default()
        })
    }
}
use super::CrdtManager;
use anyhow::Result;

pub struct CollaborativeText<'a> {
    manager: &'a mut CrdtManager,
    doc_id: String,
}

impl<'a> CollaborativeText<'a> {
    /// Criar uma nova inst√¢ncia
    pub fn new(manager: &'a mut CrdtManager, doc_id: &str) -> Self {
        Self {
            manager,
            doc_id: doc_id.to_string(),
        }
    }
    
    /// Inserir texto em uma posi√ß√£o
    pub fn insert(&mut self, index: u32, text: &str) -> Result<()> {
        self.manager.apply_local_update(&self.doc_id, |txt| {
            txt.insert(index, text);
        })
    }
    
    /// Deletar texto em um intervalo
    pub fn delete(&mut self, index: u32, length: u32) -> Result<()> {
        self.manager.apply_local_update(&self.doc_id, |txt| {
            txt.delete(index, length);
        })
    }
    
    /// Obter o texto atual
    pub fn get_text(&mut self) -> String {
        let doc = self.manager.get_or_create_document(&self.doc_id);
        
        let txn = doc.transact();
        let text = txn.get_text("text").unwrap();
        text.to_string()
    }
    
    /// Solicitar sincroniza√ß√£o com a rede
    pub fn sync(&mut self) -> Result<()> {
        self.manager.request_sync(&self.doc_id)
    }
}use std::time::Duration;
use std::sync::Arc;
use std::collections::HashMap;
use tokio::sync::RwLock;
use std::sync::atomic::{AtomicU64, Ordering};
use log::{debug, info};
use serde::{Serialize, Deserialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EnergyMetrics {
    pub current_consumption: f64,
    pub total_savings: f64,
    pub history: Vec<f64>,
    pub forecast: Option<f64>,
    pub last_updated: chrono::DateTime<chrono::Utc>,
    pub active_connections: usize,
}

impl Default for EnergyMetrics {
    fn default() -> Self {
        Self {
            current_consumption: 0.0,
            total_savings: 0.0,
            history: Vec::new(),
            forecast: None,
            last_updated: chrono::Utc::now(),
            active_connections: 0,
        }
    }
}
pub struct EnergyManager {
    tx_bytes: AtomicU64,
    rx_bytes: AtomicU64,
    node_metrics: Arc<RwLock<HashMap<String, Vec<EnergyMetrics>>>>,
    sampling_interval: Duration,
    low_power_threshold: f64,
    low_power_mode: bool,
    #[allow(dead_code)]
    baseline_metrics: Option<EnergyMetrics>,
}

impl EnergyManager {
    pub fn new() -> Self {
        Self {
            tx_bytes: AtomicU64::new(0),
            rx_bytes: AtomicU64::new(0),
            node_metrics: Arc::new(RwLock::new(HashMap::new())),
            sampling_interval: Duration::from_secs(60), 
            low_power_threshold: 0.7, 
            low_power_mode: false,
            baseline_metrics: None,
        }
    }

    pub fn with_sampling_interval(mut self, interval: Duration) -> Self {
        self.sampling_interval = interval;
        self
    }
    
    pub fn with_low_power_threshold(mut self, threshold: f64) -> Self {
        self.low_power_threshold = threshold.clamp(0.0, 1.0);
        self
    }
    
    pub fn record_tx_bytes(&self, bytes: u64) {
        self.tx_bytes.fetch_add(bytes, Ordering::Relaxed);
    }
    
    pub fn record_rx_bytes(&self, bytes: u64) {
        self.rx_bytes.fetch_add(bytes, Ordering::Relaxed);
    }
    
    pub fn get_tx_bytes(&self) -> u64 {
        self.tx_bytes.load(Ordering::Relaxed)
    }
    
    pub fn get_rx_bytes(&self) -> u64 {
        self.rx_bytes.load(Ordering::Relaxed)
    }
    
    /// Capturar m√©tricas do sistema atual
    pub async fn capture_metrics(&mut self, node_id: &str, active_connections: usize) -> EnergyMetrics {
        let cpu_usage = self.get_system_cpu_usage();
        let memory_usage = self.get_system_memory_usage();
        
        let _tx_bytes = self.tx_bytes.load(Ordering::Relaxed);
        let _rx_bytes = self.rx_bytes.load(Ordering::Relaxed);
        
        // Calcula a economia de energia com base no modo atual
        let energy_saved = if self.low_power_mode {
            // Simplifica√ß√£o: assumimos economia de 20% em modo de baixo consumo
            20.0
        } else {
            // Energia economizada √© proporcional √† diferen√ßa entre uso m√°ximo e atual
            let baseline = 100.0; // Consumo de energia de refer√™ncia (100%)
            let current_usage = 0.5 * cpu_usage + 0.3 * (memory_usage / 1000.0) + 
                              0.2 * (active_connections as f64 / 100.0);
            
            (baseline - current_usage).max(0.0)
        };
        
        let metrics = EnergyMetrics {
            current_consumption: cpu_usage,
            total_savings: energy_saved,
            history: Vec::new(),
            forecast: None,
            last_updated: chrono::Utc::now(),
            active_connections,
        };
        
        // Atualiza o modo de economia baseado no uso atual
        // Movido para antes de adquirir o lock para evitar problemas de borrowing
        self.update_power_mode(cpu_usage);
        
        // Armazena as m√©tricas no hist√≥rico
        let mut node_metrics = self.node_metrics.write().await;
        let metrics_history = node_metrics.entry(node_id.to_string()).or_insert_with(Vec::new);
        metrics_history.push(metrics.clone());
        
        // Limita o hist√≥rico a 1000 amostras por n√≥
        if metrics_history.len() > 1000 {
            metrics_history.remove(0);
        }
        
        metrics
    }
    
    /// Atualiza o modo de energia baseado na carga do sistema
    fn update_power_mode(&mut self, cpu_usage: f64) {
        let should_be_low_power = cpu_usage > self.low_power_threshold;
        
        if should_be_low_power != self.low_power_mode {
            self.low_power_mode = should_be_low_power;
            if self.low_power_mode {
                info!("Ativando modo de economia de energia devido a alta carga (CPU: {:.1}%)", cpu_usage);
            } else {
                info!("Desativando modo de economia de energia (CPU: {:.1}%)", cpu_usage);
            }
        }
    }
    
    fn get_system_cpu_usage(&self) -> f64 {
        45.0 + rand::random::<f64>() * 10.0 
    }
    
    fn get_system_memory_usage(&self) -> f64 {
        // MVP: simula√ß√£o simplificada
        // TODO: Implementar medi√ß√£o real com sys-info ou similar
        500.0 + rand::random::<f64>() * 200.0 // Entre 500MB e 700MB
    }
    
    pub async fn get_node_metrics(&self, node_id: &str) -> Option<Vec<EnergyMetrics>> {
        let node_metrics = self.node_metrics.read().await;
        node_metrics.get(node_id).cloned()
    }
    
    pub async fn get_latest_node_metrics(&self, node_id: &str) -> Option<EnergyMetrics> {
        let node_metrics = self.node_metrics.read().await;
        node_metrics.get(node_id).and_then(|metrics| metrics.last().cloned())
    }
    pub async fn get_total_energy_saved(&self) -> f64 {
        let node_metrics = self.node_metrics.read().await;
        let mut total_saved = 0.0;
        let mut node_count = 0;
        
        for metrics_vec in node_metrics.values() {
            if let Some(latest) = metrics_vec.last() {
                total_saved += latest.total_savings;
                node_count += 1;
            }
        }
        
        if node_count > 0 {
            total_saved / node_count as f64
        } else {
            0.0
        }
    }

    pub async fn start_monitoring(&self, node_id: String) {
        let _node_metrics = self.node_metrics.clone();
        let sampling_interval = self.sampling_interval;
        
        tokio::spawn(async move {
            loop {
                // No MVP, isto √© apenas um espa√ßo reservado
                // Na implementa√ß√£o real, capturaria m√©tricas regularmente
                tokio::time::sleep(sampling_interval).await;
                
                debug!("Coleta peri√≥dica de m√©tricas para o n√≥ {}", node_id);
                // Aqui capturaria m√©tricas de fato e atualizaria no hist√≥rico
            }
        });
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::time::sleep;
    
    #[tokio::test]
    async fn test_record_network_traffic() {
        let manager = EnergyManager::new();
        
        manager.record_tx_bytes(1000);
        manager.record_rx_bytes(2000);
        
        assert_eq!(manager.get_tx_bytes(), 1000);
        assert_eq!(manager.get_rx_bytes(), 2000);
        
        manager.record_tx_bytes(500);
        manager.record_rx_bytes(700);
        
        assert_eq!(manager.get_tx_bytes(), 1500);
        assert_eq!(manager.get_rx_bytes(), 2700);
    }
    
    #[tokio::test]
    async fn test_capture_metrics() {
        let mut manager = EnergyManager::new();
        
        let node_id = "test-node-1";
        let metrics = manager.capture_metrics(node_id, 10).await;
        
        assert!(metrics.current_consumption > 0.0);
        assert!(metrics.total_savings > 0.0);
        assert_eq!(metrics.active_connections, 10);
        
        let stored_metrics = manager.get_node_metrics(node_id).await.unwrap();
        assert_eq!(stored_metrics.len(), 1);
        
        let metrics2 = manager.capture_metrics(node_id, 15).await;
        assert_eq!(metrics2.active_connections, 15);
        
        let stored_metrics = manager.get_node_metrics(node_id).await.unwrap();
        assert_eq!(stored_metrics.len(), 2);
    }
    
    #[tokio::test]
    async fn test_get_latest_node_metrics() {
        let mut manager = EnergyManager::new();
        
        let node_id = "test-node-2";
        
        assert!(manager.get_latest_node_metrics(node_id).await.is_none());
        
        manager.capture_metrics(node_id, 5).await;
        sleep(Duration::from_millis(10)).await;
        let metrics2 = manager.capture_metrics(node_id, 10).await;
        
        let latest = manager.get_latest_node_metrics(node_id).await.unwrap();
        
        assert_eq!(latest.active_connections, metrics2.active_connections);
    }
    
    #[tokio::test]
    async fn test_total_energy_saved() {
        let mut manager = EnergyManager::new();
        
        assert_eq!(manager.get_total_energy_saved().await, 0.0);
        
        // Adiciona m√©tricas para dois n√≥s

        manager.capture_metrics("node-1", 10).await;
        manager.capture_metrics("node-2", 20).await;
        
        let total_saved = manager.get_total_energy_saved().await;
        assert!(total_saved > 0.0);
    }
} use anyhow::Result;
use libp2p::{
    core::transport::{OrTransport, Transport},
    identity::Keypair,
    PeerId,
    StreamMuxerBox,
};
use super::{quic, tcp};

pub async fn build_transport_with_fallback(
    local_key: &Keypair,
) -> Result<impl Transport<Output = (PeerId, StreamMuxerBox)> + Clone> {
    // Construir transporte QUIC (primeira op√ß√£o)
    let quic_transport = quic::build_quic_transport(local_key).await?;
    
    // Construir transporte TCP (fallback)
    let tcp_transport = tcp::build_tcp_transport(local_key)?;
    
    // Combinar os transportes com fallback autom√°tico
    let transport = OrTransport::new(quic_transport, tcp_transport)
        .boxed();
        
    Ok(transport)
}mod quic;
mod tcp;
mod fallback;

pub use quic::build_quic_transport;
pub use tcp::build_tcp_transport;
pub use fallback::build_fallback_transport;
pub use fallback::build_transport_with_fallback;

use anyhow::Result;
use libp2p::{
    core::transport::Transport, 
    identity::Keypair, 
    StreamMuxerBox
};

/// Constr√≥i um transporte compat√≠vel com o libp2p
pub async fn build_transport(
    local_key: &Keypair,
    enable_quic: bool,
) -> Result<impl Transport<Output = (libp2p::PeerId, StreamMuxerBox)> + Clone> {
    if enable_quic {
        build_quic_transport(local_key).await
    } else {
        build_tcp_transport(local_key)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use libp2p::PeerId;
    
    #[tokio::test]
    async fn test_build_transport_tcp() {
        let local_key = Keypair::generate_ed25519();
        let transport = build_transport(&local_key, false).await.unwrap();
        assert!(transport.boxed() != None);
    }
    
    #[tokio::test]
    async fn test_build_transport_quic() {
        let local_key = Keypair::generate_ed25519();
        let transport = build_transport(&local_key, true).await.unwrap();
        assert!(transport.boxed() != None);
    }
}use anyhow::Result;
use libp2p::{
    core::transport::Transport,
    identity::Keypair,
    quic,
    PeerId,
    StreamMuxerBox,
};

pub async fn build_quic_transport(
    local_key: &Keypair,
) -> Result<impl Transport<Output = (PeerId, StreamMuxerBox)> + Clone> {
    // Configura√ß√£o b√°sica do QUIC
    let quic_config = quic::Config::new(local_key);
    
    // Construir o transporte
    let transport = quic::tokio::Transport::new(quic_config)
        .map(|(peer_id, conn)| (peer_id, StreamMuxerBox::new(conn)))
        .boxed();
        
    Ok(transport)
}
#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_build_tcp_transport() {
        let local_key = Keypair::generate_ed25519();
        let transport = build_tcp_transport(&local_key).unwrap();
        assert!(transport != None);
    }
}// Em network/src/transport/tcp.rs

use anyhow::Result;
use libp2p::{
    core::upgrade,
    identity::Keypair,
    noise::{NoiseConfig, X25519Spec, Keypair as NoiseKeys},
    tcp::TokioTcpConfig,
    yamux::YamuxConfig,
    Transport,
};

/// Constr√≥i um transporte TCP
pub fn build_tcp_transport(
    local_key: &Keypair,
) -> Result<impl Transport<Output = (libp2p::PeerId, libp2p::StreamMuxerBox)> + Clone> {
    let noise_keys = NoiseKeys::<X25519Spec>::new()
        .into_authentic(local_key)?;
        
    let transport = TokioTcpConfig::new()
        .nodelay(true)
        .upgrade(upgrade::Version::V1)
        .authenticate(NoiseConfig::xx(noise_keys).into_authenticated())
        .multiplex(YamuxConfig::default())
        .boxed();
        
    Ok(transport)
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_build_tcp_transport() {
        let local_key = Keypair::generate_ed25519();
        let transport = build_tcp_transport(&local_key).unwrap();
        assert!(transport != None);
    }
}use libp2p::{
    gossipsub::{
        Behaviour as Gossipsub, ConfigBuilder as GossipsubConfigBuilder, MessageAuthenticity,
        ValidationMode, Event as GossipsubEvent, 
        IdentTopic as Topic, MessageId
    },
    kad::{store::MemoryStore, Behaviour as Kademlia, Config as KademliaConfig, 
          Event as KademliaEvent, QueryId, Record, RecordKey, store::RecordStore},
    mdns::{tokio::Behaviour as Mdns, Config as MdnsConfig, Event as MdnsEvent},
    swarm::NetworkBehaviour,
    identify::{Behaviour as Identify, Config as IdentifyConfig, Event as IdentifyEvent},
    PeerId, identity::Keypair
};
use anyhow::{Result, anyhow};
use std::collections::HashMap;
use std::time::Duration;
use log::{debug, info};

/// Events that can be emitted by the P2P behavior
#[derive(Debug)]
pub enum Event {
    Mdns(MdnsEvent),
    Kademlia(KademliaEvent),
    Gossipsub(GossipsubEvent),
    Identify(IdentifyEvent),
    PeerDiscovered(PeerId),
    PeerDisconnected(PeerId),
    RecordReceived(Vec<u8>, Vec<u8>), // key, value
    MessageReceived(String, Vec<u8>, PeerId), // topic, data, source
}

impl From<MdnsEvent> for Event { 
    fn from(ev: MdnsEvent) -> Self { 
        match ev {
            MdnsEvent::Discovered(peers) => {
                debug!("mDNS discovered {} peers", peers.len());
                Event::PeerDiscovered(peers[0].0)
            },
            MdnsEvent::Expired(peers) => {
                debug!("mDNS expired {} peers", peers.len());
                Event::PeerDisconnected(peers[0].0)
            }
        }
    } 
}

impl From<KademliaEvent> for Event { 
    fn from(ev: KademliaEvent) -> Self { 
        match ev {
            KademliaEvent::OutboundQueryProgressed { ref result, .. } => {
                debug!("Kademlia query completed: {:?}", result);
                Event::Kademlia(ev)
            },
            _ => Event::Kademlia(ev)
        }
    }
}

impl From<GossipsubEvent> for Event { 
    fn from(ev: GossipsubEvent) -> Self { 
        match ev {
            GossipsubEvent::Message { 
                propagation_source,
                message_id,
                ref message 
            } => {
                debug!("Gossipsub received message from {:?}: {:?}", 
                    propagation_source, message_id);
                    
                Event::MessageReceived(
                    message.topic.as_str().to_string(),
                    message.data.clone(),
                    propagation_source
                )
            },
            _ => Event::Gossipsub(ev)
        }
    } 
}

impl From<IdentifyEvent> for Event {
    fn from(ev: IdentifyEvent) -> Self {
        Event::Identify(ev)
    }
}

/// P2P behavior combining mDNS, Kademlia and Gossipsub
#[derive(NetworkBehaviour)]
#[behaviour(out_event = "Event")]
pub struct P2PBehaviour {
    pub gossipsub: Gossipsub,
    pub kademlia: Kademlia<MemoryStore>,
    pub mdns: Mdns,
    pub identify: Identify,
}

impl P2PBehaviour {
    pub async fn new(local_peer_id: PeerId, local_key: Keypair) -> Result<(Self, HashMap<String, Topic>, HashMap<QueryId, RecordKey>)> {
        // Configure Kademlia
        let store = MemoryStore::new(local_peer_id);
        let kademlia_config = KademliaConfig::default();
        let kademlia = Kademlia::with_config(local_peer_id, store, kademlia_config);
        
        // Configure Gossipsub
        let gossipsub_config = GossipsubConfigBuilder::default()
            .heartbeat_interval(Duration::from_secs(10))
            .validation_mode(ValidationMode::Strict)
            .build()
            .expect("Valid config");
        let gossipsub = Gossipsub::new(MessageAuthenticity::Signed(local_key.clone()), gossipsub_config)
            .expect("Valid configuration");
            
        // Configure mDNS
        let mdns = Mdns::new(MdnsConfig::default(), local_peer_id)?;
            
        // Configure Identify
        let identify = Identify::new(IdentifyConfig::new(
            "/atous/1.0.0".into(),
            local_key.public(),
        ));
        
        Ok((Self {
            gossipsub,
            kademlia,
            mdns,
            identify,
        },
        HashMap::new(),
        HashMap::new()))
    }
    
    pub fn subscribe(&mut self, topic: &str) -> Result<bool> {
        let topic = Topic::new(topic);
        Ok(self.gossipsub.subscribe(&topic)?)
    }
    
    pub fn unsubscribe(&mut self, topic: &str) -> Result<bool> {
        let topic = Topic::new(topic);
        Ok(self.gossipsub.unsubscribe(&topic)?)
    }
    
    pub fn publish(&mut self, topic: &str, data: Vec<u8>) -> Result<MessageId> {
        let topic = Topic::new(topic);
        Ok(self.gossipsub.publish(topic, data)?)
    }
    
    pub fn bootstrap(&mut self) -> Result<QueryId> {
        info!("Starting DHT bootstrap");
        Ok(self.kademlia.bootstrap()?)
    }
    
    pub fn store_value(&mut self, key: Vec<u8>, value: Vec<u8>) -> Result<()> {
        let record = Record {
            key: RecordKey::new(&key),
            value,
            publisher: None,
            expires: None,
        };
        
        match self.kademlia.store_mut().put(record) {
            Ok(_) => Ok(()),
            Err(e) => Err(anyhow!("Failed to store value: {}", e)),
        }
    }
    
    pub fn get_value(&mut self, key: Vec<u8>) -> Result<Option<Vec<u8>>> {
        let record_key = RecordKey::new(&key);
        if let Some(record) = self.kademlia.store_mut().get(&record_key) {
            Ok(Some(record.value.clone()))
        } else {
            Ok(None)
        }
    }
}

use crate::transport::build_transport_with_fallback;

pub async fn build_swarm(local_key: &Keypair) -> Result<Swarm<P2PBehaviour>> {
    let peer_id = PeerId::from(local_key.public());
    
    // Usar o transporte com fallback (QUIC com fallback para TCP)
    let transport = build_transport_with_fallback(local_key).await?;
    
    // Construir o behaviour
    let behaviour = P2PBehaviour::new(peer_id, local_key);
    
    // Construir e retornar o swarm
    let swarm = SwarmBuilder::new(transport, behaviour, peer_id)
        .executor(Box::new(|fut| { tokio::spawn(fut); }))
        .build();   
    Ok(swarm)
}pub mod behaviour;fn start_node() {
    let rt = Runtime::new().unwrap();
    rt.block_on(async {
        let node = establish_connection().await;
        assert!(node.is_ok());
    });
}

#[derive(NetworkBehaviour)]
struct Behaviour {
    mdns: Mdns,
}

impl Behaviour {
    fn new() -> Self {
        Behaviour {
            mdns: Mdns::new(MdnsConfig::default()).expect("Unable to create Mdns instance"),
        }
    }
}

fn stop_node() {
    let rt = Runtime::new().unwrap();
    rt.block_on(async {
        let node = stop_connection().await;
        assert!(node.is_ok());
    });
}

fn establish_connection() -> Result<(), String> {
    let behaviour = Behaviour::new();
    let swarm = SwarmBuilder::new(behaviour, PeerId::random()).build();
    Ok(())
}use super::behaviour::{P2PBehaviour, Event, P2PState};
use libp2p::{identity, PeerId};
use std::time::Duration;

#[test]
fn test_p2p_behaviour_creation() {
    let keypair = identity::Keypair::generate_ed25519();
    let local_peer_id = PeerId::from(keypair.public());
    
    // This should compile if P2PBehaviour correctly implements NetworkBehaviour
    let (behaviour, state) = P2PBehaviour::new(local_peer_id, &keypair);
    
    // Get local_peer_id through the accessor method
    assert_eq!(behaviour.get_local_peer_id(&local_peer_id), local_peer_id);
}

#[test]
fn test_connected_peers() {
    let keypair = identity::Keypair::generate_ed25519();
    let local_peer_id = PeerId::from(keypair.public());
    
    let (mut behaviour, mut state) = P2PBehaviour::new(local_peer_id, &keypair);
    let peer_id = PeerId::random();
    
    // Test connected peers operations
    assert!(!behaviour.is_connected(&peer_id, &state));
    behaviour.add_connected_peer(peer_id, &mut state);
    assert!(behaviour.is_connected(&peer_id, &state));
    let connected = behaviour.connected_peers(&state);
    assert_eq!(connected.len(), 1);
    assert_eq!(connected[0], peer_id);
    
    // Test remove peer
    behaviour.remove_connected_peer(&peer_id, &mut state);
    assert!(!behaviour.is_connected(&peer_id, &state));
    assert_eq!(behaviour.connected_peers(&state).len(), 0);
}

#[test]
fn test_topic_operations() {
    let keypair = identity::Keypair::generate_ed25519();
    let local_peer_id = PeerId::from(keypair.public());
    
    let (mut behaviour, mut state) = P2PBehaviour::new(local_peer_id, &keypair);
    let topic_name = "test-topic";
    
    // First add topic without subscription
    let result = behaviour.add_topic(topic_name, false, &mut state);
    assert!(result.is_none()); // No error
    
    // Subscribe to the topic
    let result = behaviour.subscribe_to_topic(topic_name, &mut state);
    assert!(result.is_ok());
}

#[test]
fn test_dht_operations() {
    let keypair = identity::Keypair::generate_ed25519();
    let local_peer_id = PeerId::from(keypair.public());
    
    let (mut behaviour, mut state) = P2PBehaviour::new(local_peer_id, &keypair);
    
    // Test put record
    let key = b"test-key".to_vec();
    let value = b"test-value".to_vec();
    
    let result = behaviour.put_record(key.clone(), value.clone());
    assert!(result.is_ok());
    
    // Test get record
    let query_id = behaviour.get_record(key, &mut state);
    assert!(!query_id.is_zero());
}

#[cfg(test)]
mod tests {
    use super::behaviour::{P2PBehaviour, Event, P2PState};
    use libp2p::{identity::Keypair, PeerId, gossipsub::{IdentTopic, Topic}, kad::QueryId};
    use std::time::Duration;
    use log::{debug, info, warn};
    use std::sync::{Arc, Mutex};

    #[test]
    fn test_p2p_behaviour_peers() {
        let keypair = Keypair::generate_ed25519();
        let local_peer_id = PeerId::from(keypair.public());
        let (mut behaviour, shared_state) = P2PBehaviour::new(local_peer_id, &keypair);
        let peer_id = PeerId::random();
        
        // Test connection status
        {
            let state = shared_state.lock().unwrap();
            assert!(!behaviour.is_connected(&peer_id, &state));
        }
        
        // Add connected peer
        {
            let mut state = shared_state.lock().unwrap();
            behaviour.add_connected_peer(peer_id, &mut state);
        }
        
        // Check connection is recorded
        {
            let state = shared_state.lock().unwrap();
            assert!(behaviour.is_connected(&peer_id, &state));
            let connected = behaviour.connected_peers(&state);
            assert_eq!(connected.len(), 1);
            assert_eq!(connected[0], peer_id);
        }
        
        // Remove connected peer
        {
            let mut state = shared_state.lock().unwrap();
            behaviour.remove_connected_peer(&peer_id, &mut state);
        }
        
        // Check connection is removed
        {
            let state = shared_state.lock().unwrap();
# üöÄ Sistema Atous - Identidade Descentralizada & Comunica√ß√£o Segura

![Rust](https://img.shields.io/badge/rust-1.70+-orange.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Build](https://img.shields.io/badge/build-passing-brightgreen.svg)
![Security](https://img.shields.io/badge/security-hardened-green.svg)

O **Atous** √© um sistema distribu√≠do robusto de identidade descentralizada e comunica√ß√£o segura constru√≠do em Rust, com foco em **seguran√ßa avan√ßada**, performance e escalabilidade.

## ‚ú® Caracter√≠sticas Principais

- üÜî **Identidade Descentralizada (DID)**: Sistema completo de gerenciamento de identidades
- üåê **Rede P2P**: Comunica√ß√£o peer-to-peer usando libp2p com Gossipsub e Kademlia DHT
- ‚õìÔ∏è **Blockchain**: Sistema de blockchain para transa√ß√µes e consenso distribu√≠do
- üîê **Criptografia P√≥s-Qu√¢ntica**: Algoritmos resistentes a ataques qu√¢nticos (Dilithium, ML-KEM)
- üõ°Ô∏è **Sistema de Flags**: Detec√ß√£o e resposta autom√°tica a atividades suspeitas
- ‚ö° **WebSocket**: Comunica√ß√£o em tempo real bidirecional
- üåç **API REST**: Interface completa para todas as funcionalidades
- üìä **Monitoramento**: M√©tricas Prometheus e dashboards Grafana

## üîí **SEGURAN√áA AVAN√áADA** *(Novo!)*

### **üõ°Ô∏è Stack de Seguran√ßa Multicamada**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    SECURITY MIDDLEWARE STACK                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. üìù Logging & Normalization                              ‚îÇ
‚îÇ 2. üåê CORS Protection                                       ‚îÇ
‚îÇ 3. üõ°Ô∏è SYBIL PROTECTION (Max 2 nodes/IP, 2h window)        ‚îÇ
‚îÇ 4. üîê JWT AUTHENTICATION (Bearer token required)           ‚îÇ
‚îÇ 5. ‚è±Ô∏è RATE LIMITING (10 req/min, 3 concurrent max)         ‚îÇ
‚îÇ 6. üóúÔ∏è Compression                                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ üîí PROTECTED ENDPOINTS:                                     ‚îÇ
‚îÇ   ‚Ä¢ /api/flags    ‚Üí Requires Bearer token                  ‚îÇ
‚îÇ   ‚Ä¢ /api/metrics  ‚Üí Requires Bearer token                  ‚îÇ
‚îÇ   ‚Ä¢ /api/nodes    ‚Üí Requires Bearer token                  ‚îÇ
‚îÇ   ‚Ä¢ /admin/*      ‚Üí Requires Bearer token                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ üíæ PAYLOAD LIMITS:                                          ‚îÇ
‚îÇ   ‚Ä¢ HTTP Body: 256KB max                                   ‚îÇ
‚îÇ   ‚Ä¢ JSON: 256KB max                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **üéØ Prote√ß√µes Implementadas**

- ‚úÖ **Prote√ß√£o Anti-Sybil**: M√°ximo 2 n√≥s por endere√ßo IP
- ‚úÖ **Autentica√ß√£o JWT**: Obrigat√≥ria para todos os endpoints API
- ‚úÖ **Rate Limiting**: 10 requests/minuto, 3 conex√µes concorrentes
- ‚úÖ **Prote√ß√£o de M√©tricas**: Endpoint `/api/metrics` protegido por autentica√ß√£o
- ‚úÖ **Valida√ß√£o de Payload**: Limite de 256KB para prevenir ataques DoS
- ‚úÖ **Valida√ß√£o de Assinatura**: Flags de seguran√ßa com assinatura obrigat√≥ria

## üöÄ In√≠cio R√°pido

### Instala√ß√£o em 3 Passos

```bash
# 1. Clone e compile
git clone https://github.com/seu-usuario/atous.git
cd atous
cargo build --release

# 2. Execute o sistema (com logs de seguran√ßa)
./target/release/atous-security-fixes

# 3. Teste com autentica√ß√£o
curl -H "Authorization: Bearer valid_jwt_token" http://localhost:8081/api/flags
```

### ‚úÖ Verifica√ß√£o B√°sica

```bash
# Teste sem autentica√ß√£o (deve falhar com HTTP 401)
curl http://localhost:8081/api/flags
# Expected: HTTP 401 Unauthorized - Missing Authorization header

# Teste com autentica√ß√£o v√°lida
curl -H "Authorization: Bearer valid_jwt_token" http://localhost:8081/api/flags
# Expected: HTTP 200 OK com dados

# Teste de m√©tricas protegidas
curl -H "Authorization: Bearer valid_jwt_token" http://localhost:8081/api/metrics
# Expected: HTTP 200 OK com m√©tricas
```

### üîê Autentica√ß√£o JWT

```bash
# Exemplo de request autenticado
curl -X POST http://localhost:8081/api/flags \
  -H "Authorization: Bearer valid_jwt_token" \
  -H "Content-Type: application/json" \
  -d '{"name": "test", "description": "Teste", "enabled": true}'

# Para produ√ß√£o, use tokens JWT reais
# Para testes, use o token especial: "valid_jwt_token"
```

## üìö Documenta√ß√£o Completa

### üìñ Guias Dispon√≠veis

- **[üöÄ Guia de In√≠cio R√°pido](GUIA_INICIO_RAPIDO.md)** - Configure e execute em 5 minutos
- **[üìã Documenta√ß√£o Completa](DOCUMENTACAO_COMPLETA.md)** - Guia completo com todos os endpoints e funcionalidades
- **[üèóÔ∏è Guia do Sistema](GUIA_DO_SISTEMA.md)** - Arquitetura e componentes detalhados
- **[üîß Guia T√©cnico](TECHNICAL_GUIDE.md)** - Informa√ß√µes t√©cnicas avan√ßadas

### üéØ Casos de Uso

- **Monitoramento de Seguran√ßa**: Sistema de flags para detectar atividades suspeitas
- **Comunica√ß√£o P2P**: Troca de mensagens seguras entre n√≥s
- **Gest√£o de Identidade**: Cria√ß√£o e verifica√ß√£o de identidades descentralizadas
- **Auditoria**: Registro imut√°vel de transa√ß√µes via blockchain

## üõ°Ô∏è API Endpoints Principais

> **‚ö†Ô∏è IMPORTANTE**: Todos os endpoints `/api/*` agora requerem autentica√ß√£o JWT!

### üîê Autentica√ß√£o Obrigat√≥ria
```bash
# Todas as requisi√ß√µes devem incluir o header Authorization
Authorization: Bearer <your_jwt_token>

# Para testes de desenvolvimento, use:
Authorization: Bearer valid_jwt_token
```

### Flags de Seguran√ßa üö©
```bash
GET    /api/flags              # Listar todas as flags [AUTH REQUIRED]
POST   /api/flags              # Criar flag b√°sica [AUTH REQUIRED]
POST   /api/flags/security     # Criar flag de seguran√ßa [AUTH REQUIRED]
GET    /api/flags/{id}          # Recuperar flag espec√≠fica [AUTH REQUIRED]
```

### M√©tricas de Sistema üìä
```bash
GET    /api/metrics            # M√©tricas Prometheus [AUTH REQUIRED - NOVO!]
```

### Identidades (DIDs) üÜî
```bash
POST   /api/identities         # Criar nova identidade [AUTH REQUIRED]
GET    /api/identities/{did}   # Recuperar identidade [AUTH REQUIRED]
PUT    /api/identities/{did}   # Atualizar identidade [AUTH REQUIRED]
POST   /api/identities/search  # Buscar identidades [AUTH REQUIRED]
```

### Mensagens üí¨
```bash
POST   /api/messages           # Enviar mensagem [AUTH REQUIRED]
GET    /api/messages           # Listar mensagens [AUTH REQUIRED]
GET    /api/messages/{id}      # Recuperar mensagem espec√≠fica [AUTH REQUIRED]
```

### Blockchain ‚õìÔ∏è
```bash
GET    /api/blockchain/blocks          # Listar blocos [AUTH REQUIRED]
POST   /api/blockchain/transactions    # Submeter transa√ß√£o [AUTH REQUIRED]
GET    /api/blockchain/transactions/{hash} # Recuperar transa√ß√£o [AUTH REQUIRED]
```

### üîí C√≥digos de Resposta de Seguran√ßa

| C√≥digo | Descri√ß√£o | A√ß√£o |
|--------|-----------|------|
| `401 Unauthorized` | Token JWT ausente ou inv√°lido | Incluir header `Authorization: Bearer <token>` |
| `429 Too Many Requests` | Rate limiting ativado | Aguardar antes de nova tentativa |
| `429 Too Many Requests` | Prote√ß√£o Sybil ativada | Muitos n√≥s do mesmo IP |
| `413 Payload Too Large` | Payload > 256KB | Reduzir tamanho do payload |

### üìù Exemplos de Uso com Autentica√ß√£o

```bash
# ‚úÖ Correto - Com autentica√ß√£o
curl -H "Authorization: Bearer valid_jwt_token" \
     -X GET http://localhost:8081/api/flags

# ‚ùå Incorreto - Sem autentica√ß√£o
curl -X GET http://localhost:8081/api/flags
# Retorna: HTTP 401 Unauthorized - Missing Authorization header

# ‚úÖ Criar flag de seguran√ßa
curl -H "Authorization: Bearer valid_jwt_token" \
     -H "Content-Type: application/json" \
     -X POST http://localhost:8081/api/flags/security \
     -d '{
       "name": "suspicious_activity",
       "description": "Atividade suspeita detectada",
       "enabled": true,
       "signature": "valid_signature_here"
     }'

# ‚úÖ Verificar m√©tricas do sistema
curl -H "Authorization: Bearer valid_jwt_token" \
     http://localhost:8081/api/metrics
```

## üîå WebSocket API

```javascript
const ws = new WebSocket('ws://localhost:8082/ws');

ws.onopen = function() {
    // Subscrever a eventos
    ws.send(JSON.stringify({
        type: 'subscribe',
        topics: ['messages', 'blockchain', 'security_flags']
    }));
};

ws.onmessage = function(event) {
    const data = JSON.parse(event.data);
    console.log('Evento recebido:', data);
};
```

## üß™ Testes e Valida√ß√£o

### **üîí Testes de Seguran√ßa** *(Novo!)*

```bash
# Teste completo de penetra√ß√£o
chmod +x penetration_test_suite.sh
./penetration_test_suite.sh

# Testes espec√≠ficos de seguran√ßa
chmod +x network_security_tests.sh
./network_security_tests.sh
```

**Resultados esperados dos testes de seguran√ßa:**
- ‚úÖ Rate limiting funcionando (requests bloqueados)
- ‚úÖ Autentica√ß√£o obrigat√≥ria (HTTP 401 sem token)
- ‚úÖ Prote√ß√£o Sybil ativa (m√∫ltiplos n√≥s bloqueados)
- ‚úÖ M√©tricas protegidas (HTTP 401 sem auth)
- ‚úÖ Payloads grandes rejeitados

### Script de Testes Automatizado
```bash
chmod +x atous-test-cli.sh
./atous-test-cli.sh
```

### Testes de Performance
```bash
# REST API (com autentica√ß√£o)
wrk -t12 -c100 -d30s \
    -H "Authorization: Bearer valid_jwt_token" \
    http://localhost:8081/api/flags

# Teste de rate limiting
for i in {1..15}; do
  curl -H "Authorization: Bearer valid_jwt_token" \
       http://localhost:8081/api/flags &
done
# Expectativa: Alguns requests com HTTP 429 (rate limited)
```

### üõ°Ô∏è Valida√ß√£o de Seguran√ßa Manual

```bash
# 1. Teste de autentica√ß√£o (deve falhar)
curl http://localhost:8081/api/flags
# Expected: HTTP 401 Unauthorized

# 2. Teste de autentica√ß√£o (deve funcionar)
curl -H "Authorization: Bearer valid_jwt_token" \
     http://localhost:8081/api/flags
# Expected: HTTP 200 OK

# 3. Teste de rate limiting
for i in {1..12}; do
  curl -H "Authorization: Bearer valid_jwt_token" \
       http://localhost:8081/api/flags
done
# Expected: Algumas respostas HTTP 429

# 4. Teste de payload grande (deve falhar)
curl -H "Authorization: Bearer valid_jwt_token" \
     -H "Content-Type: application/json" \
     -X POST http://localhost:8081/api/flags \
     -d "$(printf '{"data":"%*s"}' 300000 "")"
# Expected: HTTP 413 Payload Too Large

# 5. Teste de m√©tricas protegidas
curl http://localhost:8081/api/metrics
# Expected: HTTP 401 Unauthorized

curl -H "Authorization: Bearer valid_jwt_token" \
     http://localhost:8081/api/metrics
# Expected: HTTP 200 OK com dados de m√©tricas
```

## ÔøΩÔøΩ Monitoramento

### **üîí M√©tricas Prometheus Protegidas** *(Atualizado!)*

```bash
# ‚ùå ANTES: Endpoint p√∫blico (vulnerabilidade corrigida)
# curl http://localhost:9090/metrics  

# ‚úÖ AGORA: Endpoint protegido por autentica√ß√£o
curl -H "Authorization: Bearer valid_jwt_token" \
     http://localhost:8081/api/metrics
```

**Principais m√©tricas dispon√≠veis:**
- `requests_total` - Total de requests processados
- `requests_rate_limited` - Requests bloqueados por rate limiting
- `auth_failures` - Falhas de autentica√ß√£o (inclui ataques Sybil)
- `security_flags_created` - Flags de seguran√ßa criadas
- `flag_system_*` - M√©tricas do sistema de flags
- `p2p_connections_*` - Conex√µes P2P ativas
- `blockchain_*` - M√©tricas da blockchain

### **üö® M√©tricas de Seguran√ßa** *(Novo!)*

```json
{
  "requests_total": 245,
  "requests_rate_limited": 12,
  "auth_failures": 8,
  "security_flags_created": 3
}
```

### Dashboard Grafana
```bash
docker-compose up grafana
# Acesse: http://localhost:3000 (admin/admin)
```

**Dashboards de seguran√ßa inclu√≠dos:**
- üîí **Security Overview**: Vis√£o geral das tentativas de ataque
- ‚è±Ô∏è **Rate Limiting**: Monitoramento de rate limiting
- üõ°Ô∏è **Sybil Protection**: Detect√ß√£o de ataques Sybil
- üîê **Authentication**: Falhas de autentica√ß√£o por IP

### üèóÔ∏è Configura√ß√£o de Monitoramento Seguro

```yaml
# prometheus.yml atualizado
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'atous-secured'
    static_configs:
      - targets: ['localhost:8081']
    metrics_path: '/api/metrics'
    scheme: http
    # Adicionar autentica√ß√£o para Prometheus
    authorization:
      type: Bearer
      credentials: 'valid_jwt_token'  # Use token real em produ√ß√£o
```

## üê≥ Docker

### Execu√ß√£o com Docker Compose
```bash
docker-compose up -d
```

### Servi√ßos Inclu√≠dos
- **atous**: Aplica√ß√£o principal (porta 8081)
- **redis**: Cache e persist√™ncia
- **prometheus**: M√©tricas (porta 9090)
- **grafana**: Dashboards (porta 3000)

## ‚öôÔ∏è Configura√ß√£o

### Arquivo de Configura√ß√£o B√°sico

```json
{
  "node": {
    "name": "meu-node-atous",
    "mode": "Full"
  },
  "web": {
    "enabled": true,
    "port": 8081
  },
  "websocket": {
    "enabled": true,
    "port": 8082
  },
  "network": {
    "p2p_port": 8083,
    "use_dynamic_port": true
  }
}
```

### Vari√°veis de Ambiente
```bash
ATOUS_NODE_NAME=meu-node
ATOUS_LOG_LEVEL=info
ATOUS_HTTP_PORT=8081
ATOUS_WS_PORT=8082
```

## üõ†Ô∏è Desenvolvimento

### Estrutura do Projeto
```
atous/
‚îú‚îÄ‚îÄ atous/              # Aplica√ß√£o principal
‚îú‚îÄ‚îÄ network/            # Rede P2P
‚îú‚îÄ‚îÄ crypto/             # Criptografia
‚îú‚îÄ‚îÄ message/            # Sistema de mensagens
‚îú‚îÄ‚îÄ behaviour/          # Comportamentos P2P
‚îú‚îÄ‚îÄ flag-system/        # Sistema de flags
‚îî‚îÄ‚îÄ src/                # API web flags
```

### Comandos de Desenvolvimento
```bash
cargo build              # Compila√ß√£o r√°pida
cargo build --release    # Compila√ß√£o otimizada
cargo test               # Executar testes
cargo clippy            # Linter
cargo fmt               # Formata√ß√£o
```

## üö® Resolu√ß√£o de Problemas Comuns

### Porta em uso
```bash
sudo lsof -i :8081
sudo kill -9 PID
```

### Redis n√£o conecta
```bash
sudo systemctl start redis-server
redis-cli ping
```

### WebSocket falha
```bash
nc -zv localhost 8082
curl http://localhost:8081/health
```

## ü§ù Contribuindo

1. **Fork** o reposit√≥rio
2. **Crie** uma branch: `An√°lise de um Sistema de Flags com Blockchain para Isolamento de N√≥s Suspeitos no Micro-HivermindI. Introdu√ß√£oO conceito de Micro-Hivermind, descrito como um "sistema imunol√≥gico neural distribu√≠do", apresenta um paradigma intrigante para a auto-regula√ß√£o e seguran√ßa em redes descentralizadas. A proposta de integrar um sistema de flags (sinalizadores) baseado em blockchain para o isolamento de n√≥s suspeitos dentro desta arquitetura visa fornecer um mecanismo robusto, transparente e audit√°vel para a manuten√ß√£o da integridade da rede. Este relat√≥rio tem como objetivo analisar criticamente a arquitetura de tal sistema, examinar um cen√°rio de ataque simulado para testar sua resili√™ncia, e discutir a cr√≠tica levantada por David Moseler. Ser√£o detalhados os componentes, intera√ß√µes, pontos fortes e fracos, e o potencial de implementa√ß√£o, com √™nfase na explora√ß√£o de uma poss√≠vel implementa√ß√£o na linguagem de programa√ß√£o Rust, utilizando o documento "The Rust Programming Language.pdf" 1 como refer√™ncia para aspectos de implementa√ß√£o e o readme "atous" (assumido como base conceitual para a estrutura do Micro-Hivermind) como guia para a arquitetura subjacente.II. Vis√£o Geral Conceitual do Sistema de Flags PropostoA. Analogia: Sistema Imunol√≥gico Neural Distribu√≠doA met√°fora de um "sistema imunol√≥gico neural distribu√≠do" sugere uma rede capaz de detectar, identificar e neutralizar amea√ßas internas de forma aut√¥noma e coordenada, similarmente aos mecanismos de defesa biol√≥gicos. Neste contexto, os n√≥s da rede Micro-Hivermind atuam como c√©lulas, e o sistema de flags com blockchain funcionaria como um componente crucial deste sistema imunol√≥gico, permitindo que "anticorpos" (n√≥s vigilantes) marquem "pat√≥genos" (n√≥s suspeitos) e iniciem uma resposta coordenada para isol√°-los. A componente "neural" implica a capacidade de aprendizado e adapta√ß√£o do sistema, possivelmente atrav√©s da an√°lise de padr√µes de comportamento sinalizados.B. Papel da Blockchain: Imutabilidade, Transpar√™ncia e Consenso DescentralizadoA utiliza√ß√£o de uma blockchain como alicerce para o sistema de flags oferece vantagens significativas. Primeiramente, a imutabilidade garante que, uma vez que uma flag √© registrada e validada, ela n√£o pode ser alterada ou removida subrepticiamente, fornecendo um hist√≥rico √≠ntegro das atividades suspeitas.2 Em segundo lugar, a transpar√™ncia inerente √† maioria das implementa√ß√µes de blockchain permite que todos os n√≥s (ou pelo menos os n√≥s autorizados) auditem o registro de flags, promovendo a responsabilidade e dificultando a censura ou manipula√ß√£o oculta. Finalmente, um mecanismo de consenso descentralizado √© fundamental para validar as flags antes que a√ß√µes punitivas, como o isolamento de um n√≥, sejam tomadas.3 Isso evita que um √∫nico n√≥ ou um pequeno grupo mal-intencionado possa comprometer a rede atrav√©s de falsas acusa√ß√µes.C. Conceito Central do SistemaO fluxo operacional b√°sico do sistema proposto envolve:
Detec√ß√£o e Gera√ß√£o de Flags: N√≥s individuais no Micro-Hivermind monitoram o comportamento de seus pares. Ao detectar uma atividade que viole as regras predefinidas do protocolo ou que seja considerada maliciosa (por exemplo, envio de dados corrompidos, falha em participar do consenso, ataques de nega√ß√£o de servi√ßo), um n√≥ pode gerar uma flag.
Registro na Blockchain: A flag gerada, contendo informa√ß√µes sobre o n√≥ sinalizador, o n√≥ suspeito, a natureza da suspeita e evid√™ncias (possivelmente um hash da evid√™ncia), √© submetida para inclus√£o na blockchain.
Valida√ß√£o por Consenso: A rede de n√≥s (ou um subconjunto de validadores) utiliza um mecanismo de consenso para verificar a validade da flag e das evid√™ncias associadas.
A√ß√£o de Isolamento: Se um n√∫mero suficiente de flags validadas contra um n√≥ espec√≠fico for acumulado, ou se uma √∫nica flag de alta severidade for confirmada, o sistema pode acionar um protocolo de isolamento para aquele n√≥.
Este ciclo cont√≠nuo de monitoramento, sinaliza√ß√£o, valida√ß√£o e resposta constitui o n√∫cleo do "sistema imunol√≥gico" proposto.III. Arquitetura Detalhada do Sistema de Flags Baseado em BlockchainA. N√≥ do Micro-Hivermind (Baseado nos Princ√≠pios do "atous")Embora o readme "atous" n√£o tenha sido fornecido, pode-se inferir que um n√≥ do Micro-Hivermind possui funcionalidades centrais que interagem com o subsistema de flags.
Funcionalidades Essenciais: Cada n√≥ √© presumivelmente respons√°vel por tarefas computacionais espec√≠ficas do dom√≠nio do Micro-Hivermind (potencialmente relacionadas a processamento neural distribu√≠do), comunica√ß√£o com outros n√≥s para troca de dados e participa√ß√£o em processos colaborativos.
Intera√ß√£o com o Subsistema de Flags:

Monitoramento: Implementa l√≥gica para observar o comportamento de n√≥s vizinhos ou n√≥s com os quais interage, comparando-o com um conjunto de comportamentos esperados ou aceit√°veis.
Gera√ß√£o de Flags: Ao detectar anomalias, o n√≥ constr√≥i uma estrutura de dados de flag e a submete √† camada de blockchain.
Participa√ß√£o no Consenso: Dependendo do mecanismo de consenso, o n√≥ pode participar da valida√ß√£o de flags submetidas por outros.
Aplica√ß√£o de Isolamento: Recebe e processa decis√µes de isolamento validadas pela blockchain, ajustando suas tabelas de roteamento ou listas de permiss√£o para evitar intera√ß√µes com o n√≥ isolado.


B. Mecanismo de Flagging
Gera√ß√£o de Flags:

Crit√©rios: Devem ser claramente definidos e objetivamente verific√°veis para minimizar falsos positivos. Exemplos incluem: falha em responder a heartbeats, envio de dados malformados, desvio estat√≠stico significativo no comportamento esperado, falha em seguir protocolos de consenso.
Evid√™ncia: Cada flag deve ser acompanhada de evid√™ncias que a corroborem. Para economizar espa√ßo na blockchain, a evid√™ncia completa pode ser armazenada off-chain (por exemplo, em um sistema de arquivos distribu√≠do como IPFS), com apenas seu hash criptogr√°fico inclu√≠do na flag na blockchain.4


Estrutura da Flag: Uma flag pode ser representada como uma estrutura de dados contendo campos como:

flagger_id: Identificador √∫nico do n√≥ que gera a flag.
suspect_id: Identificador √∫nico do n√≥ suspeito.
timestamp: Momento da detec√ß√£o da anomalia.
evidence_hash: Hash da evid√™ncia que suporta a flag.
reason_code: Um c√≥digo enumerado indicando o tipo de mau comportamento (por exemplo, MALFORMED_DATA, NON_RESPONSIVE, CONSENSUS_VIOLATION).
severity_level: Um indicador da gravidade da infra√ß√£o.
signature: Assinatura digital do flagger_id para autenticar a origem da flag.


Propaga√ß√£o de Flags: As flags geradas precisam ser disseminadas pela rede para que possam ser inclu√≠das em um bloco e validadas. Isso ocorreria atrav√©s do protocolo de comunica√ß√£o P2P da pr√≥pria blockchain subjacente.
C. Camada da Blockchain
Estrutura do Ledger: A blockchain consistiria em uma cadeia de blocos, onde cada bloco conteria um conjunto de transa√ß√µes de flags.2 Cada transa√ß√£o de flag representaria uma flag submetida.
Mecanismo de Consenso para Valida√ß√£o de Flags: A escolha do mecanismo de consenso √© cr√≠tica e impacta a seguran√ßa, escalabilidade e efici√™ncia do sistema.

Proof of Work (PoW): Altamente seguro e testado, mas consome muita energia e pode ter alta lat√™ncia.7 Seria custoso para simplesmente validar flags.
Proof of Stake (PoS): Mais eficiente energeticamente que PoW, onde validadores apostam suas moedas. Suscet√≠vel a diferentes vetores de ataque se n√£o implementado cuidadosamente.7 Poderia ser vi√°vel se os n√≥s do Micro-Hivermind tiverem um stake no sistema.
Proof of Execution (PoE): Um protocolo BFT que visa alcan√ßar consenso resiliente com fases lineares, utilizando execu√ß√£o especulativa e rollbacks seguros.9 PoE √© apresentado como escal√°vel e protetor contra ataques maliciosos, podendo ser uma op√ß√£o interessante se a "execu√ß√£o" se referir √† valida√ß√£o da evid√™ncia da flag. No entanto, a defini√ß√£o de PoE varia, com algumas fontes focando em "Proof of Evidence" para garantir oportunidades iguais de valida√ß√£o 10 ou verifica√ß√£o de computa√ß√£o, incluindo cargas de trabalho n√£o determin√≠sticas como IA.11 Se a "execu√ß√£o" no Micro-Hivermind se refere a tarefas computacionais que podem ser verificadas, PoE poderia ser relevante para validar o comportamento do n√≥ em geral, e n√£o apenas as flags.
Practical Byzantine Fault Tolerance (PBFT): Um algoritmo de consenso cl√°ssico para sistemas distribu√≠dos que toleram falhas bizantinas. Pode ter alta sobrecarga de comunica√ß√£o em redes grandes.3
A escolha depender√° dos requisitos espec√≠ficos do Micro-Hivermind em termos de lat√™ncia, throughput, seguran√ßa e complexidade. Um mecanismo leve e r√°pido, possivelmente um PoS ou uma variante de BFT otimizada para este caso de uso, parece mais apropriado do que PoW.


Smart Contracts para L√≥gica de Flags (Opcional): Smart contracts poderiam automatizar a l√≥gica de processamento de flags. Por exemplo, um smart contract poderia agregar flags contra um n√≥, verificar se um limiar foi atingido e, ent√£o, emitir um evento de isolamento ou at√© mesmo acionar mecanismos de penalidade (como slashing de stake em um sistema PoS).
D. Protocolo de Isolamento de N√≥
Crit√©rios para Isolamento: Definidos pelo sistema, por exemplo:

Um n√∫mero N de flags validadas de M fontes √∫nicas.
Uma √∫nica flag validada de um tipo de severidade cr√≠tica.
Uma pontua√ß√£o de reputa√ß√£o do n√≥ caindo abaixo de um limiar, onde as flags contribuem negativamente para a pontua√ß√£o.


M√©todos de Isolamento:

N√≠vel de Rede: Outros n√≥s podem ser instru√≠dos (via blockchain ou um canal de controle) a adicionar o IP do n√≥ isolado a uma lista de bloqueio em seus firewalls locais ou a recusar conex√µes dele. A intera√ß√£o com o sistema operacional para tal pode ser feita via std::process::Command em Rust para executar utilit√°rios como iptables ou ip link set down, ou, com mais complexidade e risco, via FFI (extern "C") para chamar APIs de C do sistema operacional.1
N√≠vel de Aplica√ß√£o: Os n√≥s do Micro-Hivermind podem manter uma lista de n√≥s isolados e se recusar a processar mensagens ou interagir com eles em n√≠vel de aplica√ß√£o.


Reavalia√ß√£o/Reintegra√ß√£o: Deve haver um mecanismo para que um n√≥ isolado possa, eventualmente, ser reavaliado e potencialmente reintegrado √† rede. Isso pode envolver um per√≠odo de "quarentena", a submiss√£o de uma prova de corre√ß√£o de comportamento, ou um voto da rede.
E. Merkle Trees para Compacta√ß√£o e Verifica√ß√£o de EstadoMerkle trees s√£o estruturas de dados em √°rvore onde cada n√≥ folha √© um hash de um bloco de dados, e cada n√≥ n√£o-folha √© um hash de seus filhos.4 O hash raiz (Merkle root) representa de forma compacta a integridade de todos os dados subjacentes.4
Papel na Verifica√ß√£o Eficiente: No sistema de flags, Merkle trees podem ser usadas para:

Verificar a inclus√£o de flags em um bloco: Semelhante a como transa√ß√µes s√£o verificadas em blockchains como Bitcoin e Ethereum, o Merkle root de todas as flags em um bloco pode ser inclu√≠do no cabe√ßalho do bloco. Isso permite que n√≥s leves verifiquem a inclus√£o de uma flag espec√≠fica baixando apenas o cabe√ßalho do bloco e um pequeno Merkle proof (um caminho de hashes da flag at√© a raiz), em vez do bloco inteiro.2
Verificar a integridade de evid√™ncias off-chain: Se as evid√™ncias detalhadas s√£o armazenadas off-chain, seus hashes (que est√£o na blockchain) podem ser organizados em uma Merkle tree. O Merkle root dessa √°rvore de evid√™ncias pode ser referenciado pela flag, permitindo uma verifica√ß√£o eficiente da integridade da evid√™ncia.
Compacta√ß√£o do estado geral do sistema: Se o sistema mant√©m um estado agregado sobre a reputa√ß√£o dos n√≥s ou o status das flags, uma Merkle tree pode ser usada para representar esse estado de forma compacta. Compara√ß√µes de Merkle roots entre n√≥s podem rapidamente detectar inconsist√™ncias.4


Compacta√ß√£o de Logs de Flags ou Hashes de Evid√™ncias: Em vez de armazenar uma longa lista de hashes de evid√™ncias diretamente na blockchain para cada flag complexa, esses hashes podem formar as folhas de uma Merkle tree, e apenas o Merkle root dessa √°rvore seria armazenado na blockchain. Isso reduz significativamente os requisitos de armazenamento on-chain.13 Algumas propostas, como QMDB, unificam o estado mundial e o armazenamento da Merkle tree, persistindo atualiza√ß√µes em um log de acr√©scimo e usando "galhos" (twigs) para comprimir a √°rvore, permitindo que ela caiba na DRAM.13
A utiliza√ß√£o de Merkle trees √© fundamental para a escalabilidade e efici√™ncia na verifica√ß√£o de dados em sistemas distribu√≠dos e blockchains.2IV. Cen√°rio de Ataque Simulado: Ataque Sybil com N√≥s ConluiadosA. Descri√ß√£o do Cen√°rioUm ataque Sybil ocorre quando um advers√°rio cria um grande n√∫mero de identidades pseud√¥nimas (n√≥s Sybil) e as utiliza para ganhar uma influ√™ncia desproporcional na rede.7 Neste cen√°rio simulado, um grupo de n√≥s Sybil conluiados coopera para gerar um volume massivo de flags falsas ou enganosas contra um ou mais n√≥s-alvo honestos. O objetivo do ataque pode ser desacreditar os n√≥s-alvo, causar seu isolamento indevido, ou perturbar o funcionamento normal do Micro-Hivermind.B. Resposta Esperada do SistemaO sistema de flags baseado em blockchain deve possuir mecanismos para resistir a tal ataque:
Custo de Gera√ß√£o de Identidade/Flag: Se a cria√ß√£o de identidades de n√≥s ou a submiss√£o de flags tiver um custo (por exemplo, exigir um stake em um sistema PoS, ou uma pequena taxa de transa√ß√£o), isso pode tornar ataques Sybil em larga escala economicamente invi√°veis.
Requisitos de Evid√™ncia: Flags sem evid√™ncias cr√≠veis ou com evid√™ncias facilmente falsific√°veis devem ser rejeitadas pelo processo de consenso. A robustez da evid√™ncia √© crucial.
Consenso sobre Flags: O mecanismo de consenso n√£o deve ser facilmente dominado pelos n√≥s Sybil.

Em PoS, os n√≥s Sybil precisariam adquirir uma quantidade significativa de stake, o que pode ser caro.7
Em sistemas baseados em reputa√ß√£o (se aplic√°vel ao Micro-Hivermind), novas identidades Sybil teriam baixa reputa√ß√£o e suas flags teriam menos peso.
Mecanismos BFT como PBFT ou PoE s√£o projetados para tolerar uma certa fra√ß√£o de n√≥s maliciosos (geralmente f falhas em n>3f r√©plicas).9 Os n√≥s Sybil precisariam controlar mais do que essa fra√ß√£o de poder de voto no consenso.


Diversidade de Sinalizadores: O protocolo de isolamento pode exigir flags de m√∫ltiplas fontes independentes e com boa reputa√ß√£o, em vez de apenas um grande volume de flags de n√≥s novos ou com baixa reputa√ß√£o. Se as flags dos n√≥s Sybil forem correlacionadas (por exemplo, todas sinalizando o mesmo evento benigno como malicioso), o "sistema neural" poderia aprender a identificar esse padr√£o de conluio.
An√°lise de Padr√µes de Flagging: O componente "neural" do sistema imunol√≥gico poderia ser treinado para detectar padr√µes anormais de flagging, como um aumento s√∫bito de flags de um grupo de n√≥s rec√©m-chegados ou geograficamente correlacionados, indicando um poss√≠vel ataque Sybil.
C. An√°lise de Resili√™nciaA resili√™ncia do sistema a este ataque depende criticamente:
Robustez do Mecanismo de Consenso: Um consenso que seja dif√≠cil e caro de ser dominado por uma minoria (mesmo uma grande minoria de Sybils) √© essencial.
Qualidade e Verificabilidade da Evid√™ncia: Se a evid√™ncia for forte e dif√≠cil de forjar, as flags falsas ser√£o mais facilmente identificadas.
Custo de Participa√ß√£o e Sinaliza√ß√£o: Impor custos (financeiros ou computacionais) para criar n√≥s e submeter flags desencoraja a prolifera√ß√£o de Sybils.
Intelig√™ncia do Sistema de Isolamento: Regras de isolamento que considerem a reputa√ß√£o dos sinalizadores, a diversidade das fontes de flags e a gravidade/qualidade da evid√™ncia s√£o mais resilientes do que contagens simples de flags.
Capacidade de Adapta√ß√£o (Componente Neural): Se o sistema puder aprender e adaptar seus crit√©rios de detec√ß√£o e isolamento com base em ataques passados ou padr√µes anormais, sua resili√™ncia aumentar√° ao longo do tempo.
Um sistema bem projetado pode tornar um ataque Sybil com flags falsas proibitivamente caro ou complexo para o atacante, ou detectar e mitigar o ataque antes que danos significativos ocorram. No entanto, nenhum sistema √© imune a ataques Sybil suficientemente grandes e bem financiados, especialmente se os custos de participa√ß√£o forem baixos.V. An√°lise da Cr√≠tica de David MoselerAssumindo que a cr√≠tica de David Moseler ao sistema proposto se concentre em preocupa√ß√µes comuns a sistemas baseados em blockchain aplicados √† modera√ß√£o ou detec√ß√£o de anomalias, os pontos prov√°veis seriam:A. Resumo da Cr√≠tica (Pontos Hipot√©ticos)
Lat√™ncia: A necessidade de registrar flags na blockchain e aguardar a confirma√ß√£o do consenso pode introduzir lat√™ncia significativa, tornando o sistema lento para responder a amea√ßas em tempo real.
Sobrecarga Computacional e de Armazenamento: Manter uma blockchain para flags, executar o consenso e armazenar o hist√≥rico de flags pode impor uma sobrecarga consider√°vel aos n√≥s do Micro-Hivermind, desviando recursos de suas tarefas prim√°rias.
Risco de Falsos Positivos e Negativos:

Falsos Positivos: N√≥s honestos podem ser sinalizados incorretamente devido a falhas de rede transit√≥rias, bugs de software ou interpreta√ß√µes err√¥neas de comportamento, levando ao seu isolamento injusto.
Falsos Negativos: N√≥s maliciosos podem evadir a detec√ß√£o por meio de comportamentos sutis ou explorando as limita√ß√µes dos crit√©rios de flagging.


Complexidade da Implementa√ß√£o e Manuten√ß√£o: Introduzir uma camada de blockchain e um sistema de flags complexo adiciona uma sobrecarga significativa de desenvolvimento, teste e manuten√ß√£o ao ecossistema Micro-Hivermind.
Centraliza√ß√£o Potencial no Consenso: Dependendo do mecanismo de consenso escolhido (por exemplo, DPoS ou PoA), pode haver um risco de centraliza√ß√£o do poder de valida√ß√£o das flags, minando o prop√≥sito de um sistema descentralizado.3
B. Validade dos Pontos LevantadosEsses pontos s√£o, em geral, preocupa√ß√µes v√°lidas para muitos sistemas baseados em blockchain:
Lat√™ncia e Sobrecarga: S√£o inerentes √† maioria das blockchains, especialmente aquelas que priorizam a seguran√ßa e a descentraliza√ß√£o sobre o throughput bruto. O impacto depender√° da frequ√™ncia de flags, do tamanho da rede e da efici√™ncia do mecanismo de consenso.
Falsos Positivos/Negativos: Este √© um desafio fundamental em qualquer sistema de detec√ß√£o de anomalias ou sistema imunol√≥gico. A precis√£o depende da qualidade dos crit√©rios de flagging e da robustez das evid√™ncias.
Complexidade: A introdu√ß√£o de uma blockchain √©, inegavelmente, um aumento de complexidade.
Centraliza√ß√£o do Consenso: √â uma preocupa√ß√£o real para certos mecanismos de consenso e deve ser cuidadosamente considerada na escolha do algoritmo.3
C. Mitiga√ß√µes Potenciais ou Contra-Argumentos
Lat√™ncia:

Utilizar blockchains de alta performance ou sidechains/layer-2 solutions especificamente para o sistema de flags.
Permitir a√ß√µes de isolamento preliminares baseadas em um n√∫mero menor de flags n√£o totalmente confirmadas (com risco aumentado de falsos positivos), enquanto a confirma√ß√£o final ocorre na blockchain principal.
Mecanismos de consenso mais r√°pidos como PoE ou algumas variantes de PoS podem oferecer menor lat√™ncia.9


Sobrecarga:

Otimizar a estrutura de dados das flags e blocos.
Usar Merkle trees para compactar dados e permitir verifica√ß√£o eficiente com provas leves.4
Designar um subconjunto de n√≥s mais capazes para atuar como validadores de flags, reduzindo a carga sobre todos os n√≥s.
O armazenamento de evid√™ncias off-chain √© crucial.4


Falsos Positivos/Negativos:

Implementar um sistema de reputa√ß√£o para os n√≥s sinalizadores; flags de n√≥s com alta reputa√ß√£o teriam mais peso.
Exigir m√∫ltiplas flags de fontes diversas e independentes antes de tomar medidas dr√°sticas.
Desenvolver crit√©rios de flagging sofisticados, possivelmente usando t√©cnicas de aprendizado de m√°quina (o aspecto "neural" do Micro-Hivermind).
Estabelecer um processo claro de apela√ß√£o ou reavalia√ß√£o para n√≥s isolados.


Complexidade:

Utilizar frameworks ou bibliotecas Rust existentes para componentes da blockchain (P2P, consenso, armazenamento) pode reduzir a complexidade da implementa√ß√£o.1
Adotar uma abordagem de implementa√ß√£o incremental, come√ßando com funcionalidades mais simples.


Centraliza√ß√£o do Consenso:

Escolher mecanismos de consenso que promovam maior descentraliza√ß√£o (por exemplo, PoS com baixas barreiras de entrada para validadores) ou que tenham garantias formais contra a centraliza√ß√£o.
Implementar mecanismos de governan√ßa para monitorar e mitigar a centraliza√ß√£o no conjunto de validadores.


A cr√≠tica de Moseler, embora hipot√©tica aqui, provavelmente apontaria para os desafios pr√°ticos e os trade-offs inerentes √† adi√ß√£o de uma camada de blockchain. A viabilidade do sistema depender√° de qu√£o bem esses desafios s√£o abordados no projeto e na implementa√ß√£o.VI. Avalia√ß√£o Abrangente: Pontos Fortes, Fracos e Trade-offsA proposta de um sistema de flags baseado em blockchain para o Micro-Hivermind apresenta um conjunto distinto de vantagens e desvantagens que devem ser cuidadosamente ponderadas.A. Pontos Fortes
Imutabilidade e Auditabilidade: O registro de flags em uma blockchain garante que, uma vez confirmadas, as sinaliza√ß√µes n√£o podem ser alteradas ou exclu√≠das secretamente. Isso cria um rastro de auditoria transparente e confi√°vel, essencial para an√°lises forenses e para construir confian√ßa no sistema.2
Transpar√™ncia: As flags e as decis√µes de isolamento podem ser publicamente verific√°veis (ou verific√°veis por todos os participantes da rede), o que aumenta a responsabilidade e dificulta comportamentos maliciosos ocultos.10
Resist√™ncia √† Censura: Em um sistema descentralizado, √© mais dif√≠cil para um ator malicioso suprimir a sinaliza√ß√£o de seu pr√≥prio mau comportamento ou o de seus c√∫mplices.
Consenso Descentralizado para Decis√µes Cr√≠ticas: A valida√ß√£o de flags e a decis√£o de isolar um n√≥ s√£o tomadas por um consenso distribu√≠do, em vez de uma autoridade central, o que aumenta a resili√™ncia contra pontos √∫nicos de falha ou comprometimento.3
Potencial para Mecanismos de Incentivo: A blockchain pode facilitar a implementa√ß√£o de mecanismos de incentivo (por exemplo, recompensas em tokens) para n√≥s que participam ativamente e honestamente do processo de flagging e valida√ß√£o, e penalidades (por exemplo, slashing) para sinaliza√ß√µes falsas ou maliciosas.
B. Pontos Fracos
Lat√™ncia: A confirma√ß√£o de transa√ß√µes em uma blockchain (necess√°ria para validar flags) pode levar de segundos a minutos, ou at√© mais, dependendo da blockchain e do mecanismo de consenso. Isso pode ser muito lento para uma resposta imunol√≥gica r√°pida a amea√ßas √°geis.8
Escalabilidade: O throughput (n√∫mero de flags processadas por segundo) de uma blockchain √© geralmente limitado. Se o n√∫mero de flags geradas for alto, a blockchain pode se tornar um gargalo.
Sobrecarga Computacional e de Armazenamento: Cada n√≥ que participa da valida√ß√£o ou que mant√©m uma c√≥pia completa da blockchain de flags incorre em custos computacionais (para processar transa√ß√µes e executar o consenso) e de armazenamento.8
Complexidade de Implementa√ß√£o e Manuten√ß√£o: Desenvolver, implantar e manter uma infraestrutura de blockchain √© significativamente mais complexo do que sistemas centralizados ou abordagens mais simples de detec√ß√£o de anomalias.
Risco de Falsos Positivos e Negativos:

Falsos Positivos: N√≥s honestos podem ser incorretamente sinalizados, levando ao seu isolamento injusto. O processo de apela√ß√£o pode ser lento ou complexo.
Falsos Negativos: Agentes maliciosos podem encontrar maneiras de operar abaixo do radar dos crit√©rios de flagging ou explorar as complexidades do sistema.


Vulnerabilidades do Consenso: Nenhum mecanismo de consenso √© perfeitamente seguro. Ataques de 51% (em PoW/PoS) ou conluios de validadores podem comprometer a integridade do processo de valida√ß√£o de flags.7
Custo Operacional: Pode haver custos associados √† execu√ß√£o de transa√ß√µes na blockchain (taxas de g√°s em algumas plataformas) ou √† manuten√ß√£o da infraestrutura de valida√ß√£o.
C. Trade-offs Chave
Seguran√ßa vs. Performance/Lat√™ncia: Mecanismos de consenso mais seguros e descentralizados (como PoW) tendem a ser mais lentos e menos escal√°veis. Escolhas que favorecem a velocidade podem comprometer a seguran√ßa ou a descentraliza√ß√£o.
Descentraliza√ß√£o vs. Efici√™ncia: Um alto grau de descentraliza√ß√£o na valida√ß√£o de flags aumenta a resili√™ncia, mas pode ser menos eficiente do que sistemas com um conjunto menor e mais controlado de validadores.
Transpar√™ncia vs. Privacidade: Embora a transpar√™ncia seja uma for√ßa, ela pode revelar informa√ß√µes sobre as estrat√©gias de detec√ß√£o ou sobre os n√≥s que est√£o sendo monitorados, o que pode ser explorado por advers√°rios. T√©cnicas avan√ßadas de privacidade podem ser necess√°rias para mitigar isso (discutidas na Se√ß√£o VIII).
Complexidade vs. Robustez: A complexidade adicional da blockchain visa aumentar a robustez e a confiabilidade, mas tamb√©m introduz mais pontos potenciais de falha ou vetores de ataque se n√£o for implementada e gerenciada corretamente.
A tabela a seguir resume os pontos fortes e fracos:Tabela 1: Pontos Fortes e Fracos do Sistema de Flags com Blockchain
Caracter√≠stica/AspectoPonto FortePonto FracoMitiga√ß√£o/Considera√ß√£oImutabilidade/AuditabilidadeRegistros de flags n√£o podem ser alterados; hist√≥rico confi√°vel.2--Transpar√™nciaFlags e decis√µes podem ser publicamente verific√°veis.10Pode revelar estrat√©gias de detec√ß√£o.T√©cnicas de privacidade (ZKPs, HE); acesso restrito √† blockchain de flags.Resist√™ncia √† CensuraDif√≠cil suprimir flags em um sistema descentralizado.--Consenso DescentralizadoDecis√µes cr√≠ticas tomadas pela rede, n√£o por uma entidade central.3Vulnerabilidades espec√≠ficas do mecanismo de consenso escolhido (ex: ataque 51%).7Escolha cuidadosa do mecanismo de consenso; monitoramento da distribui√ß√£o de poder.Lat√™ncia-Confirma√ß√£o de flags pode ser lenta para respostas r√°pidas.8Blockchains de alta performance; Layer-2; mecanismos de consenso r√°pidos; a√ß√µes preliminares off-chain.Escalabilidade-Throughput limitado pode ser um gargalo para alto volume de flags.Solu√ß√µes de escalabilidade de blockchain; otimiza√ß√£o de dados de flags; Merkle trees.4Sobrecarga (Comp./Armaz.)-Custo para n√≥s participantes.8Validadores dedicados; evid√™ncias off-chain; Merkle trees.4Complexidade-Aumento significativo na complexidade do sistema.Uso de bibliotecas/frameworks existentes; implementa√ß√£o incremental.Falsos Positivos/Negativos-Risco inerente a sistemas de detec√ß√£o; pode levar a isolamento injusto.Crit√©rios de flagging robustos; sistema de reputa√ß√£o; m√∫ltiplas fontes de flags; processo de apela√ß√£o.Custo OperacionalPotencial para incentivos.Taxas de transa√ß√£o; manuten√ß√£o da infraestrutura.Escolha de blockchain com baixas taxas; otimiza√ß√£o.
A decis√£o de adotar tal sistema requer uma avalia√ß√£o cuidadosa desses trade-offs no contexto espec√≠fico dos objetivos de seguran√ßa, desempenho e resili√™ncia do Micro-Hivermind.VII. Proposta de Implementa√ß√£o em RustRust, com seu foco em seguran√ßa de mem√≥ria, concorr√™ncia e desempenho, √© uma linguagem promissora para a implementa√ß√£o de um sistema de flags baseado em blockchain para o Micro-Hivermind.1 Suas caracter√≠sticas podem ser mapeadas para os diversos componentes do sistema.A. Estruturas de Dados 1Rust oferece tipos robustos para definir as estruturas de dados necess√°rias:
Informa√ß√µes do N√≥, Flags, Blocos: structs s√£o ideais para representar essas entidades complexas com campos nomeados.1 Por exemplo:
Rust// Exemplo de estrutura para uma Flag
pub struct Flag {
    flagger_id: String, // Ou um tipo de ID mais espec√≠fico
    suspect_id: String,
    timestamp: u64,
    evidence_hash: String, // Hash da evid√™ncia
    reason_code: FlagReason, // Enum para tipos de mau comportamento
    severity: u8,
    signature: Vec<u8>, // Assinatura digital
}

// Exemplo de estrutura para um Bloco na blockchain de flags
pub struct FlagBlock {
    previous_hash: String,
    timestamp: u64,
    flags: Vec<Flag>, // Vetor de flags inclu√≠das neste bloco
    merkle_root: String, // Merkle root das flags no bloco
    nonce: u64, // Para PoW, se aplic√°vel
}


Tipos de Flags, Estados de N√≥s: enums s√£o perfeitos para representar um conjunto finito de estados ou tipos, como FlagReason ou NodeStatus.1
Rustpub enum FlagReason {
    MalformedData,
    NonResponsive,
    ConsensusViolation,
    //... outros motivos
}


Listas de Flags em Blocos, Logs: Vec<T> (vetores) s√£o usados para cole√ß√µes de tamanho vari√°vel de itens do mesmo tipo, como Vec<Flag> dentro de um FlagBlock ou Vec<LogEntry> para logs.1
Identificadores, Hashes, Mensagens de Log: String para dados textuais de tamanho vari√°vel. Para hashes, um tipo de array de tamanho fixo (por exemplo, [u8; 32] para SHA-256) ou uma String formatada hexadecimalmente pode ser usado.1
Mapeamento de Reputa√ß√£o de N√≥s, √çndices: HashMap<K, V> para estruturas de mapeamento eficientes, como HashMap<NodeId, ReputationScore>.1
A natureza estaticamente tipada de Rust e seu sistema de propriedade garantem que essas estruturas de dados sejam usadas de maneira segura em termos de mem√≥ria.1B. Traits para Comportamento Compartilhado 1Traits s√£o fundamentais em Rust para definir interfaces e comportamento compartilhado, permitindo polimorfismo.
Defini√ß√£o de Comportamentos: Poderiam ser definidos traits como FlaggableBehavior (para comportamentos que podem ser sinalizados), ConsensusParticipant (para n√≥s que participam da valida√ß√£o de flags), ou EvidenceHandler (para m√≥dulos que processam evid√™ncias).
Rustpub trait FlagValidator {
    fn validate(&self, flag: &Flag, evidence: &[u8]) -> Result<(), ValidationError>;
}


Polimorfismo com impl Trait e Trait Objects (dyn Trait):

Fun√ß√µes gen√©ricas usando impl Trait podem aceitar qualquer tipo que implemente um trait espec√≠fico, permitindo que, por exemplo, uma fun√ß√£o process_flag(validator: &impl FlagValidator, flag: &Flag) funcione com diferentes implementa√ß√µes de validadores.1
Para cole√ß√µes heterog√™neas (por exemplo, uma lista de diferentes tipos de regras de valida√ß√£o), Box<dyn FlagValidator> (um trait object) pode ser usado. Isso permite armazenar diferentes tipos que implementam o mesmo trait em uma √∫nica Vec, utilizando despacho din√¢mico.1 Isso √© particularmente √∫til se o sistema precisar carregar diferentes m√≥dulos de valida√ß√£o dinamicamente.


C. Modelo de Concorr√™ncia 1O Micro-Hivermind, sendo um sistema distribu√≠do, exigir√° um manejo cuidadoso da concorr√™ncia para comunica√ß√£o entre n√≥s, processamento de flags e execu√ß√£o do consenso.
Threads: Para tarefas computacionalmente intensivas (CPU-bound), como valida√ß√£o criptogr√°fica de evid√™ncias ou algumas etapas do consenso (por exemplo, minera√ß√£o em PoW, se escolhido), std::thread::spawn pode ser usado para executar trabalho em paralelo.1
Message Passing (mpsc channels): Para comunica√ß√£o segura entre threads dentro de um mesmo n√≥ (por exemplo, um thread de rede passando flags recebidas para um thread de processamento de consenso), canais mpsc (multiple producer, single consumer) s√£o uma excelente op√ß√£o, garantindo que os dados sejam transferidos com seguran√ßa e evitando condi√ß√µes de corrida.1
Shared State (Arc<Mutex<T>>): Para dados que precisam ser acessados e potencialmente modificados por m√∫ltiplos threads (por exemplo, o estado atual da blockchain de flags, uma tabela de reputa√ß√£o de n√≥s), Arc<Mutex<T>> permite o compartilhamento seguro. Arc (Atomic Reference Counting) permite m√∫ltiplos propriet√°rios dos dados, e Mutex (Mutual Exclusion) garante que apenas um thread possa acessar os dados por vez para modifica√ß√£o.1
Async/Await (async fn, Future, Tasks): Para opera√ß√µes I/O-bound, como comunica√ß√£o de rede P2P para propaga√ß√£o de flags e blocos, ou intera√ß√µes com armazenamento, o modelo async/await de Rust √© altamente eficiente.1 Ele permite que um n√≥ gerencie muitas conex√µes de rede concorrentes com um n√∫mero menor de threads do sistema operacional, usando tarefas leves gerenciadas por um executor (runtime) ass√≠ncrono.
Seguran√ßa na Concorr√™ncia em Rust: Rust garante a seguran√ßa na concorr√™ncia ("fearless concurrency") atrav√©s de seu sistema de propriedade e verifica√ß√£o de empr√©stimos em tempo de compila√ß√£o, juntamente com os traits Send (tipos cuja propriedade pode ser transferida entre threads) e Sync (tipos para os quais √© seguro ter refer√™ncias compartilhadas entre threads).1 Isso previne a maioria das condi√ß√µes de corrida e deadlocks em tempo de compila√ß√£o.
Uma abordagem h√≠brida, utilizando async/await para a camada de rede e possivelmente threads dedicadas para tarefas de consenso ou valida√ß√£o intensivas, √© uma estrat√©gia comum e eficaz em Rust. A escolha entre executar uma tarefa em um thread do sistema operacional ou como uma tarefa ass√≠ncrona depende se a tarefa √© predominantemente limitada por CPU ou por I/O.1D. Tratamento de Erros 1Opera√ß√µes de rede, intera√ß√µes com blockchain e a l√≥gica de apply_* (por exemplo, aplicar uma regra de isolamento) s√£o propensas a falhas.
Result<T, E>: Para erros recuper√°veis (por exemplo, falha na conex√£o de rede, flag inv√°lida, evid√™ncia ausente), as fun√ß√µes devem retornar Result<T, E>. Isso for√ßa o c√≥digo chamador a lidar explicitamente com a possibilidade de falha.1
Rust// Exemplo de fun√ß√£o que pode falhar
fn submit_flag_to_network(flag: &Flag) -> Result<(), NetworkError> {
    //... l√≥gica de submiss√£o...
    // if success { Ok(()) } else { Err(NetworkError::Timeout) }
    unimplemented!();
}


panic!: Para erros irrecuper√°veis que indicam um bug no programa (por exemplo, um estado interno inconsistente que n√£o deveria ocorrer), panic! pode ser usado para encerrar o programa imediatamente.1 No entanto, em um n√≥ de servidor, geralmente √© prefer√≠vel retornar Err sempre que poss√≠vel para permitir que o sistema de n√≠vel superior decida como lidar com a falha, em vez de derrubar o n√≥ inteiro.
Operador ?: Simplifica a propaga√ß√£o de erros. Se uma fun√ß√£o retorna Result, o operador ? pode ser usado em chamadas a outras fun√ß√µes que retornam Result. Se a chamada interna retornar Err(e), a fun√ß√£o atual retornar√° Err(e) imediatamente (com convers√£o de tipo de erro, se necess√°rio, via trait From).1 Isso mant√©m o c√≥digo de tratamento de erros limpo e conciso.
E. L√≥gica de Intera√ß√£o com a BlockchainIsso envolveria:
Cria√ß√£o de Transa√ß√µes de Flags: Construir a estrutura de dados da flag, serializ√°-la e submet√™-la √† rede.
Valida√ß√£o de Blocos/Flags: Implementar a l√≥gica do mecanismo de consenso escolhido. Isso pode envolver verificar assinaturas, validar evid√™ncias (potencialmente uma tarefa complexa), e garantir que as regras do protocolo de flags sejam seguidas.
Participa√ß√£o no Consenso: Se o n√≥ for um validador, ele precisar√° executar o protocolo de consenso para concordar sobre o pr√≥ximo bloco de flags.
F. Serializa√ß√£o/Deserializa√ß√£o 1Para comunica√ß√£o de rede (enviar/receber flags e blocos) e para persist√™ncia de dados (armazenar o estado da blockchain), as estruturas de dados precisar√£o ser serializadas (convertidas para um formato de bytes/string) e desserializadas.
Embora o livro "The Rust Programming Language" n√£o detalhe bibliotecas espec√≠ficas como JSON ou Serde, ele discute os traits e macros que as habilitam.1
No ecossistema Rust, a biblioteca serde (com serde_json para JSON, bincode para bin√°rio, etc.) √© o padr√£o de fato.15 Ela usa traits (Serialize, Deserialize) e macros de deriva√ß√£o (#) para gerar automaticamente o c√≥digo de serializa√ß√£o/desserializa√ß√£o para structs e enums definidos pelo usu√°rio.1 Isso torna o processo eficiente e com pouco boilerplate.
G. Intera√ß√£o em N√≠vel de SO para Isolamento de N√≥s 1Se o isolamento de um n√≥ suspeito requer manipula√ß√£o direta de interfaces de rede ou regras de firewall no sistema operacional:
std::process::Command: Esta √© geralmente a abordagem mais segura e simples. O programa Rust pode executar utilit√°rios de linha de comando do sistema operacional (como ip link set <interface> down ou iptables -A INPUT -s <IP_suspeito> -j DROP). O Rust pode capturar a sa√≠da e os erros desses comandos.1
Rustuse std::process::Command;

fn block_ip(ip_address: &str) -> std::io::Result<()> {
    let status = Command::new("iptables")
       .arg("-A")
       .arg("INPUT")
       .arg("-s")
       .arg(ip_address)
       .arg("-j")
       .arg("DROP")
       .status()?;

    if status.success() {
        Ok(())
    } else {
        Err(std::io::Error::new(std::io::ErrorKind::Other, "Failed to execute iptables"))
    }
}


FFI (extern "C"): Para intera√ß√µes de mais baixo n√≠vel ou de maior desempenho, fun√ß√µes de bibliotecas C do sistema operacional que controlam a rede podem ser chamadas diretamente. Isso requer o uso de blocos unsafe e um manuseio cuidadoso de tipos de dados C e ponteiros crus, pois o compilador Rust n√£o pode garantir a seguran√ßa dessas chamadas.1
A escolha entre std::process::Command e FFI depender√° do n√≠vel de controle necess√°rio, das considera√ß√µes de desempenho e da complexidade da API C subjacente.A implementa√ß√£o do sistema de flags pode se beneficiar significativamente da abordagem de ciclo de vida de flags utilizando o padr√£o de projeto State, como discutido no Cap√≠tulo 18 de "The Rust Programming Language".1 Cada estado de uma flag (por exemplo, Pendente, Validada, Rejeitada, A√ß√£oTomada) poderia ser um tipo que implementa um trait FlagState. Isso tornaria a l√≥gica de transi√ß√£o entre estados mais expl√≠cita e segura, alinhando-se com a √™nfase de Rust em sistemas de tipos fortes para garantir a corre√ß√£o.Ademais, a decis√£o sobre o modelo de concorr√™ncia (ou a combina√ß√£o deles) √© fundamental. A natureza distribu√≠da e potencialmente I/O-intensiva da comunica√ß√£o de flags e da sincroniza√ß√£o da blockchain sugere que async/await seria ben√©fico para a escalabilidade. No entanto, as opera√ß√µes de valida√ß√£o de flags ou a execu√ß√£o do consenso podem ser CPU-intensivas, onde threads tradicionais poderiam ser mais apropriadas. Rust permite essa combina√ß√£o de forma segura.Finalmente, embora a constru√ß√£o de uma blockchain completa a partir do zero em Rust seja uma tarefa consider√°vel, o ecossistema Rust oferece v√°rias bibliotecas e frameworks maduros (por exemplo, Substrate, Libp2p) que poderiam ser aproveitados para componentes como a camada de rede P2P, mecanismos de consenso ou implementa√ß√µes de Merkle tree. Isso poderia reduzir drasticamente o tempo de desenvolvimento e aumentar a robustez, aproveitando c√≥digo j√° testado e auditado pela comunidade.A tabela a seguir mapeia as funcionalidades de Rust aos componentes do sistema de flags:Tabela 2: Mapeamento de Funcionalidades de Rust para Componentes do Sistema de Flags do Micro-Hivermind
Componente/Requisito do SistemaFuncionalidade(s) Relevante(s) de RustRaz√£o/Benef√≠cioSnippets Chave Estruturas de Dados de Flags/Blocosstruct, enumDefini√ß√£o de tipos de dados complexos e seguros.Cap. 5, 6, 8; 1Listas de Flags, LogsVec<T>Cole√ß√µes din√¢micas de tamanho vari√°vel.Cap. 8; 1Identificadores, HashesString, [u8; N]Representa√ß√£o de dados textuais e bin√°rios.Cap. 8; 1Comportamento Compartilhado (Valida√ß√£o, Isolamento)trait, dyn TraitPolimorfismo, interfaces para diferentes implementa√ß√µes.Cap. 10, 18; 1Comunica√ß√£o Inter-N√≥s (P2P)async/await, std::net (base para P2P), mpsc (interno ao n√≥)Rede concorrente e eficiente.Cap. 16, 17, 21; 1L√≥gica de ConsensoArc<Mutex<T>>, threads, async/awaitImplementa√ß√£o de algoritmos de consenso concorrentes e seguros.Cap. 16, 17; 1Valida√ß√£o de FlagsFun√ß√µes, match, Result<T,E>L√≥gica de verifica√ß√£o e tratamento de resultados.Cap. 6, 9; 1Manipula√ß√£o de Evid√™nciasVec<u8>, String, Fun√ß√µes de Hash (externas)Processamento e verifica√ß√£o de dados de evid√™ncia.Cap. 8Persist√™ncia de Estadostd::fs, Serializa√ß√£o (Serde)Leitura/escrita do estado da blockchain em disco.Cap. 12; 1Isolamento em N√≠vel de SOstd::process::Command, extern "C" (FFI)Intera√ß√£o com utilit√°rios de sistema ou APIs de baixo n√≠vel.Cap. 20; 1Processamento Concorrentethreads, async/await, mpsc, Arc<Mutex<T>>Execu√ß√£o paralela e concorrente de tarefas.Cap. 16, 17; 1Tratamento de ErrosResult<T, E>, panic!, ?Gerenciamento robusto de falhas.Cap. 9; 1
VIII. Considera√ß√µes Avan√ßadas de Seguran√ßa e PrivacidadePara um sistema como o Micro-Hivermind, que visa operar como um "sistema imunol√≥gico neural distribu√≠do", considera√ß√µes avan√ßadas de seguran√ßa e privacidade s√£o fundamentais, especialmente ao lidar com sinaliza√ß√µes de comportamento potencialmente sens√≠veis.A. Explorando Provas de Conhecimento Zero (Zero-Knowledge Proofs - ZKPs) para Opera√ß√µes de Flag Privadas

Conceito: Provas de Conhecimento Zero (ZKPs) s√£o protocolos criptogr√°ficos que permitem a uma parte (o provador) convencer outra parte (o verificador) de que uma afirma√ß√£o √© verdadeira, sem revelar qualquer informa√ß√£o al√©m da validade da pr√≥pria afirma√ß√£o.17 As propriedades chave s√£o completude (se a afirma√ß√£o √© verdadeira, um provador honesto convence um verificador honesto), solidez (se a afirma√ß√£o √© falsa, nenhum provador desonesto pode convencer um verificador honesto) e conhecimento zero (o verificador n√£o aprende nada al√©m da validade da afirma√ß√£o).18


Aplica√ß√£o ao Sistema de Flags:

Submiss√£o Privada de Flags: Um n√≥ poderia submeter uma flag ou evid√™ncia de suporte usando ZKPs. Isso permitiria ao n√≥ provar que as condi√ß√µes para a flag foram atendidas (por exemplo, "o n√≥ X enviou dados que violam o formato Y" ou "observei o comportamento Z que corresponde a um padr√£o malicioso conhecido") sem revelar dados sens√≠veis sobre suas pr√≥prias opera√ß√µes, o conte√∫do exato da comunica√ß√£o interceptada, ou a natureza espec√≠fica do comportamento observado que poderia expor suas capacidades de detec√ß√£o.17 Isso poderia proteger os n√≥s sinalizadores de retalia√ß√£o e manter a confidencialidade de certas intera√ß√µes.
Verifica√ß√£o Privada de A√ß√µes de N√≥s: Um n√≥ poderia usar ZKPs para provar que executou corretamente uma tarefa computacional (relevante para a fun√ß√£o "neural" do Hivermind) ou que n√£o realizou uma a√ß√£o maliciosa espec√≠fica, sem ter que expor seu estado interno ou logs detalhados.14 Por exemplo, um n√≥ acusado de n√£o participar do consenso poderia provar que participou sem revelar os detalhes de seus votos ou mensagens de consenso.
Autentica√ß√£o com Preserva√ß√£o de Privacidade: ZKPs podem ser usados para autenticar n√≥s ou mensagens sem transmitir senhas ou chaves secretas.17



Tipos (zk-SNARKs vs. zk-STARKs):

zk-SNARKs (Zero-Knowledge Succinct Non-Interactive Argument of Knowledge): Produzem provas pequenas e t√™m verifica√ß√£o r√°pida, mas geralmente requerem uma "configura√ß√£o confi√°vel" (trusted setup). Se o segredo dessa configura√ß√£o for comprometido, a seguran√ßa do sistema pode ser quebrada.21 S√£o vulner√°veis a computadores qu√¢nticos devido √† sua depend√™ncia de criptografia de curva el√≠ptica.21
zk-STARKs (Zero-Knowledge Scalable Transparent Argument of Knowledge): N√£o requerem configura√ß√£o confi√°vel (s√£o "transparentes"), usam aleatoriedade p√∫blica e s√£o baseados em fun√ß√µes de hash, tornando-os resistentes a ataques qu√¢nticos. Contudo, tendem a ter tamanhos de prova maiores e podem ter um custo computacional mais alto para a gera√ß√£o da prova.21



Desafios: A implementa√ß√£o de ZKPs √© complexa e a gera√ß√£o de provas pode ser computacionalmente intensiva para o provador (o n√≥ que sinaliza ou se defende).17 A verifica√ß√£o, embora geralmente mais r√°pida, ainda adiciona sobrecarga.

B. Explorando Criptografia Homom√≥rfica (Homomorphic Encryption - HE) para An√°lise de Comportamento de N√≥s com Preserva√ß√£o de Privacidade

Conceito: A Criptografia Homom√≥rfica (HE) permite que computa√ß√µes sejam realizadas diretamente em dados criptografados, sem a necessidade de descriptograf√°-los primeiro. O resultado da computa√ß√£o, quando descriptografado, √© o mesmo que se as opera√ß√µes tivessem sido realizadas nos dados em texto plano.23


Aplica√ß√£o ao Sistema de Flags/Imunol√≥gico:

An√°lise Agregada de Amea√ßas: O "sistema imunol√≥gico neural" poderia analisar dados de flags criptografados ou relat√≥rios de comportamento de m√∫ltiplos n√≥s. Por exemplo, os n√≥s poderiam submeter contagens criptografadas de certos tipos de eventos suspeitos. O sistema poderia agregar essas contagens criptografadas (usando as propriedades aditivas da HE) para identificar padr√µes de ataque generalizados ou n√≥s maliciosos em conluio, sem que qualquer entidade (incluindo o pr√≥prio analisador central, se houver) veja os dados brutos e descriptografados de n√≥s individuais.24
An√°lise Privada de Logs: Se os n√≥s submeterem logs criptografados (por exemplo, logs de erros ou de comunica√ß√£o), a HE poderia permitir certos tipos de an√°lise (como contar a frequ√™ncia de tipos espec√≠ficos de erros ou identificar anomalias estat√≠sticas) sem descriptografar os logs completos, protegendo assim a privacidade operacional de cada n√≥.25
Treinamento de Modelos Neurais com Privacidade: Se o componente "neural" do sistema imunol√≥gico envolver aprendizado de m√°quina, a HE poderia, teoricamente, permitir o treinamento de modelos em dados agregados criptografados, embora isso seja uma √°rea de pesquisa muito ativa e com desafios significativos de desempenho.



Tipos:

Partially Homomorphic Encryption (PHE): Suporta um tipo de opera√ß√£o (adi√ß√£o ou multiplica√ß√£o), mas n√£o ambas.
Somewhat Homomorphic Encryption (SHE): Suporta um n√∫mero limitado de opera√ß√µes de adi√ß√£o e multiplica√ß√£o.25
Fully Homomorphic Encryption (FHE): Suporta um n√∫mero arbitr√°rio de opera√ß√µes de adi√ß√£o e multiplica√ß√£o, oferecendo m√°xima flexibilidade, mas √© a mais intensiva computacionalmente.24



Desafios: A HE, especialmente a FHE, √© extremamente intensiva em termos computacionais e de dados (os textos cifrados s√£o muito maiores que os textos planos).25 O desempenho pode ser um grande obst√°culo para respostas em tempo real do sistema imunol√≥gico. Esquemas mais leves de SHE ou PHE, ou t√©cnicas que combinam HE com outras abordagens como Verifiable Computation (VC) para formar Verifiable Homomorphic Encryption (VHE) 28, podem ser mais vi√°veis para computa√ß√µes espec√≠ficas e limitadas. A VHE visa garantir tanto a privacidade (via HE) quanto a integridade do resultado da computa√ß√£o (via VC).29

A integra√ß√£o de ZKPs ou HE no Micro-Hivermind representaria um avan√ßo significativo em dire√ß√£o a sistemas distribu√≠dos comprovadamente seguros e privados. No entanto, isso colocaria o sistema na vanguarda da complexidade de implementa√ß√£o e dos desafios de desempenho. A escolha de usar ZKPs ou HE influenciaria profundamente o design da estrutura de dados da Flag, o processo de submiss√£o de evid√™ncias e as capacidades computacionais exigidas dos n√≥s. Por exemplo, a gera√ß√£o de ZKPs pode ser intensiva em recursos para o n√≥ provador.O aspecto "neural" do sistema imunol√≥gico poderia ser treinado sobre os resultados de dados processados com HE (estat√≠sticas agregadas criptografadas) ou sobre padr√µes derivados de intera√ß√µes verificadas por ZKP (mas cujo conte√∫do permanece privado). Isso permitiria ao sistema aprender e adaptar-se sem comprometer a privacidade dos dados brutos dos n√≥s individuais.A tabela a seguir compara estas t√©cnicas criptogr√°ficas avan√ßadas:Tabela 3: Compara√ß√£o de T√©cnicas Criptogr√°ficas Avan√ßadas para Seguran√ßa/Privacidade Aprimoradas
T√©cnica Criptogr√°ficaDescri√ß√£oAplica√ß√£o Potencial no Sistema de FlagsPr√≥sContras/DesafiosSnippets RelevantesProvas de Conhecimento Zero (zk-SNARKs)Provas sucintas, n√£o interativas, que validam uma afirma√ß√£o sem revelar dados.Submiss√£o privada de flags; verifica√ß√£o privada de a√ß√µes de n√≥s.Provas pequenas; verifica√ß√£o r√°pida.Requer configura√ß√£o confi√°vel (geralmente); vulner√°vel a computadores qu√¢nticos.21Provas de Conhecimento Zero (zk-STARKs)Provas escal√°veis, transparentes (sem configura√ß√£o confi√°vel), que validam uma afirma√ß√£o sem revelar dados.Submiss√£o privada de flags; verifica√ß√£o privada de a√ß√µes de n√≥s.Transparente (sem configura√ß√£o confi√°vel); resistente a computadores qu√¢nticos.Provas maiores que zk-SNARKs; pode ser mais custoso computacionalmente para gerar.21Criptografia Homom√≥rfica (Parcial/Um Pouco - PHE/SHE)Permite um n√∫mero limitado ou tipos espec√≠ficos de computa√ß√µes em dados criptografados.An√°lise estat√≠stica simples de flags criptografadas; contagem de eventos espec√≠ficos.Menos sobrecarga computacional que FHE; pode ser vi√°vel para tarefas limitadas.Funcionalidade limitada; ainda pode ser lenta para tempo real.25Criptografia Homom√≥rfica (Totalmente - FHE)Permite um n√∫mero arbitr√°rio de adi√ß√µes e multiplica√ß√µes em dados criptografados.An√°lise complexa e agregada de comportamento de n√≥s sobre dados de flags criptografados; treinamento privado de modelos neurais (te√≥rico).M√°xima flexibilidade computacional em dados criptografados.Extremamente intensiva computacionalmente; textos cifrados grandes; impratic√°vel para muitas aplica√ß√µes em tempo real atualmente.24
IX. Conclus√£o e Recomenda√ß√µes Estrat√©gicasA. Avalia√ß√£o Geral de ViabilidadeA proposta de um sistema de flags baseado em blockchain para o isolamento de n√≥s suspeitos no Micro-Hivermind √© tecnicamente vi√°vel, alinhando-se bem com a necessidade de um mecanismo de "sistema imunol√≥gico neural distribu√≠do" que seja transparente, audit√°vel e resistente √† manipula√ß√£o. A imutabilidade e o consenso descentralizado oferecidos pela blockchain s√£o pontos fortes significativos para a integridade do sistema de flags. A linguagem Rust, com suas garantias de seguran√ßa de mem√≥ria e capacidades de concorr√™ncia robustas, √© uma escolha adequada para a implementa√ß√£o de tal sistema.1No entanto, a viabilidade pr√°tica depende crucialmente da gest√£o dos trade-offs inerentes. A lat√™ncia da blockchain e a sobrecarga computacional s√£o as principais preocupa√ß√µes que precisam ser mitigadas atrav√©s de escolhas de design inteligentes, como mecanismos de consenso eficientes, armazenamento de evid√™ncias off-chain e o uso de Merkle trees para compacta√ß√£o e verifica√ß√£o.4 O risco de falsos positivos e a complexidade geral do sistema tamb√©m s√£o fatores que exigem aten√ß√£o cont√≠nua.O sistema √© particularmente vi√°vel se:
A criticidade da integridade e da auditabilidade das flags superar as preocupa√ß√µes com a lat√™ncia imediata para todos os tipos de amea√ßas.
Os recursos computacionais dos n√≥s do Micro-Hivermind forem suficientes para lidar com a sobrecarga da participa√ß√£o na blockchain (ou se um subconjunto de n√≥s puder lidar com essa carga).
O "componente neural" do sistema puder ser efetivamente treinado para refinar os crit√©rios de flagging e reduzir falsos positivos/negativos.
B. Recomenda√ß√µes Acion√°veis para Refinamento do Design e Implementa√ß√£o
Mecanismo de Consenso: Priorizar mecanismos de consenso leves e r√°pidos (por exemplo, PoS com baixa barreira, ou um BFT otimizado como algumas variantes de PoE) em vez de PoW, para minimizar lat√™ncia e consumo de energia para a valida√ß√£o de flags. A pesquisa sobre PoE, especialmente suas variantes que lidam com execu√ß√£o especulativa e rollbacks, pode ser promissora para um sistema que precisa reagir a comportamentos din√¢micos.9
Estrutura e Evid√™ncia da Flag:

Implementar uma estrutura de Flag rica em Rust, utilizando enums para reason_code e structs para metadados.1
Armazenar evid√™ncias detalhadas off-chain (por exemplo, IPFS) e incluir apenas hashes na blockchain, verificados por Merkle proofs.4


L√≥gica de Isolamento: Definir limiares de isolamento que considerem a severidade da flag, o n√∫mero de flags distintas e a reputa√ß√£o dos sinalizadores. Implementar o isolamento em n√≠vel de SO via std::process::Command em Rust para maior seguran√ßa inicial.1
Implementa√ß√£o em Rust:

Utilizar structs e enums para modelar os dados da blockchain e das flags.1
Empregar traits para definir comportamentos como ValidatableFlag ou IsolatableNode, usando dyn Trait para cole√ß√µes heterog√™neas se necess√°rio.1 Adotar o padr√£o State para gerenciar o ciclo de vida das flags.1
Adotar uma arquitetura concorrente h√≠brida: async/await para I/O de rede (propaga√ß√£o de flags/blocos) e threads 1 para tarefas CPU-bound (valida√ß√£o de consenso, processamento de evid√™ncias).1
Utilizar Result<T, E> e o operador ? extensivamente para um tratamento de erros robusto.1
Empregar serde para serializa√ß√£o/desserializa√ß√£o de dados de rede e armazenamento.1
Considerar o uso de bibliotecas Rust existentes para componentes da blockchain (por exemplo, libp2p para a camada de rede, ou frameworks de blockchain como Substrate para uma base mais completa) para acelerar o desenvolvimento e aumentar a robustez.


Abordagem Incremental: Iniciar com um sistema de flags mais simples, talvez com um consenso centralizado ou federado, e evoluir para uma descentraliza√ß√£o maior e mecanismos mais sofisticados √† medida que o sistema amadurece e os requisitos de desempenho s√£o melhor compreendidos.
M√©tricas de Sucesso: Definir m√©tricas claras para avaliar a efic√°cia do sistema imunol√≥gico (por exemplo, tempo para detectar e isolar n√≥s maliciosos, taxa de falsos positivos, impacto no desempenho da rede) antes da implementa√ß√£o completa.
C. Dire√ß√µes Futuras de Pesquisa
Desempenho e Escalabilidade: Realizar benchmarking de diferentes mecanismos de consenso e configura√ß√µes da blockchain no contexto espec√≠fico das cargas de trabalho e da topologia de rede do Micro-Hivermind. Investigar os limites de escalabilidade do sistema √† medida que o n√∫mero de n√≥s e a frequ√™ncia de flags aumentam.
Integra√ß√£o com o "Componente Neural": Explorar como o sistema de flags pode alimentar dados para o aprendizado e adapta√ß√£o do sistema imunol√≥gico neural. Isso pode envolver o desenvolvimento de modelos de ML para prever comportamentos maliciosos, refinar dinamicamente os crit√©rios de flagging ou otimizar as estrat√©gias de isolamento.
Privacidade Avan√ßada: Investigar a viabilidade e os trade-offs de incorporar ZKPs para submiss√£o privada de flags ou HE para an√°lise agregada de comportamento, √† medida que essas tecnologias amadurecem e se tornam mais acess√≠veis em termos de desempenho e complexidade de implementa√ß√£o.17
Verifica√ß√£o Formal: Para componentes cr√≠ticos do sistema, especialmente a l√≥gica de consenso e os smart contracts (se utilizados), explorar o uso de t√©cnicas de verifica√ß√£o formal para provar matematicamente sua corre√ß√£o e seguran√ßa.
Mecanismos de Reintegra√ß√£o Sofisticados: Desenvolver protocolos robustos e justos para a reavalia√ß√£o e potencial reintegra√ß√£o de n√≥s isolados, possivelmente envolvendo provas de corre√ß√£o de comportamento ou per√≠odos de observa√ß√£o.
Em suma, a proposta de um sistema de flags com blockchain para o Micro-Hivermind √© um empreendimento ambicioso e promissor. Seu sucesso depender√° de um design cuidadoso que equilibre os ideais de seguran√ßa e descentraliza√ß√£o com as realidades pr√°ticas de desempenho e complexidade, e de uma implementa√ß√£o robusta que aproveite ao m√°ximo as capacidades da linguagem Rust.{
  "network": {
    "port": 8080,
    "websocket_port": 8080,
    "listen_addresses": ["0.0.0.0"],
    "bootstrap_nodes": [],
    "connection_limits": {
      "max_incoming": 100,
      "max_outgoing": 50,
      "inbound_timeout_ms": 10000,
      "outbound_timeout_ms": 10000
    },
    "security": {
      "enable_kad_firewall": true,
      "peer_reputation_enabled": true,
      "sybil_protection": {
        "enabled": true,
        "inbound_connection_rate_limit": 20,
        "min_peer_age_hours": 2
      },
      "eclipse_protection": {
        "enabled": true,
        "min_distance_threshold": 0.3,
        "min_diversity_threshold": 5
      }
    }
  },
  "websocket": {
    "enabled": true,
    "port": 8080,
    "cors": {
      "allowed_origins": ["http://localhost:3000"],
      "allowed_methods": ["GET", "POST"],
      "allowed_headers": ["Content-Type", "Authorization"],
      "max_age_seconds": 86400
    },
    "rate_limiting": {
      "enabled": true,
      "requests_per_minute": 100,
      "burst_size": 20
    }
  },
  "authentication": {
    "jwt_secret": "CHANGE_THIS_TO_A_RANDOM_SECRET_IN_PRODUCTION",
    "token_expiry_seconds": 86400,
    "did_verification": {
      "required": true,
      "methods": ["web", "blockchain", "key"]
    }
  },
  "encryption": {
    "default_enabled": true,
    "algorithms": ["chacha20poly1305", "aes256gcm"],
    "post_quantum": {
      "enabled": true,
      "algorithms": ["ml-kem-768"]
    }
  },
  "storage": {
    "data_dir": "./data",
    "persistent": true,
    "max_message_age_days": 30
  },
  "logging": {
    "level": "info",
    "file": "atous.log",
    "console": true,
    "metrics": {
      "enabled": true,
      "port": 9090
    }
  }
} {
  "node": {
    "name": "atous-node-1",
    "mode": "Full",
    "data_path": "./data",
    "log_level": "info"
  },
  "network": {
    "p2p_listen": "/ip4/127.0.0.1/tcp/8083",
    "p2p_port": 8083,
    "bootstrap_peers": [],
    "enable_mdns": true,
    "enable_kademlia": true,
    "use_dynamic_port": false,
    "port": 8083,
    "websocket_port": 8082,
    "listen_addresses": ["127.0.0.1"],
    "connection_limits": {
      "max_incoming": 100,
      "max_outgoing": 50,
      "inbound_timeout_ms": 10000,
      "outbound_timeout_ms": 10000
    },
    "security": {
      "enable_kad_firewall": true,
      "peer_reputation_enabled": true,
      "sybil_protection": {
        "enabled": true,
        "inbound_connection_rate_limit": 20,
        "min_peer_age_hours": 2
      },
      "eclipse_protection": {
        "enabled": true,
        "min_distance_threshold": 0.3,
        "min_diversity_threshold": 5
      }
    }
  },
  "websocket": {
    "enabled": true,
    "port": 8082,
    "cors": {
      "allowed_origins": ["*"],
      "allowed_methods": ["GET", "POST"],
      "allowed_headers": ["Content-Type", "Authorization"],
      "max_age_seconds": 86400
    },
    "rate_limiting": {
      "enabled": true,
      "requests_per_minute": 120,
      "burst_size": 20
    }
  },
  "authentication": {
    "jwt_secret": "distributed_secure_key_2024_atous_neural_immune_system",
    "token_expiry_seconds": 86400,
    "did_verification": {
      "required": true,
      "methods": ["web", "blockchain", "key"]
    }
  },
  "encryption": {
    "default_enabled": true,
    "algorithms": ["chacha20poly1305", "aes256gcm"],
    "post_quantum": {
      "enabled": true,
      "algorithms": ["ml-kem-768"]
    }
  },
  "storage": {
    "data_dir": "./data",
    "persistent": true,
    "max_message_age_days": 30
  },
  "logging": {
    "level": "info",
    "file": "atous.log",
    "console": true,
    "metrics": {
      "enabled": true,
      "port": 9090
    }
  },
  "web": {
    "enabled": true,
    "listen": "0.0.0.0",
    "port": 8081,
    "enable_cors": true,
    "cors_origins": ["http://localhost:3000", "https://localhost:3000"],
    "api_path": "/api"
  },
  "blockchain": {
    "enabled": true,
    "consensus": "PoW",
    "difficulty": 4,
    "block_time": 60,
    "reward": 50,
    "path": "./data/blockchain",
    "max_tx_per_block": 1000,
    "consensus_difficulty": 4
  },
  "persistence": {
    "enabled": true,
    "type": "rocksdb",
    "path": "./data/db",
    "redis_url": "redis://localhost:6379",
    "redis_pool_size": 10,
    "redis_key_prefix": "atous",
    "cache_ttl": 3600
  },
  "security": {
    "public_key_path": "./keys/public_key.pem",
    "private_key_path": "./keys/private_key.pem",
    "pqc_algorithm": "Dilithium",
    "jwt_ttl": 3600
  },
  "metrics": {
    "enabled": true,
    "port": 9090,
    "path": "/metrics"
  }
} [graph]
# If 1 or more target triples (and optionally, target_features) are specified,
# only the specified targets will be checked when running `cargo deny check`.
# This means, if a particular package is only ever used as a target specific
# dependency, such as, for example, `winapi` or `nix`, a problem with that package
# will not cause `cargo deny check` to fail unless the target is explicitly
# specified in this list.
targets = [
    # The triple can be any string, but only the target triples built in to
    # rustc (as of 1.40) can be checked against actual config
    "x86_64-unknown-linux-gnu",
    "aarch64-unknown-linux-gnu",
    "x86_64-pc-windows-msvc",
    "x86_64-apple-darwin",
]
# The feature set, if any, to use for the crate. If not specified, all features
# are used.
all-features = false
# The feature set, if any, to use for the crate. This is mutually exclusive with `all-features`.
# features = []
# If set to true, `cargo deny check` will not error if there are unused dependencies.
exclude-dev = false

[licenses]
# List of explicitly allowed licenses
allow = [
    "MIT",
    "Apache-2.0",
    "Apache-2.0 WITH LLVM-exception",
    "BSD-2-Clause",
    "BSD-3-Clause",
    "ISC",
    "Unicode-DFS-2016",
]
# List of explicitly disallowed licenses
deny = [
    "GPL-2.0",
    "GPL-3.0",
    "AGPL-1.0",
    "AGPL-3.0",
]
# Lint level for when multiple versions of the same license are detected
multiple-versions = "warn"
# Confidence threshold for detecting a license from a license text.
# Expressed as a floating point number in (0.0, 1.0] range, with
# 1.0 meaning perfect confidence
confidence-threshold = 0.8
# Allow 1 or more licenses on a per-crate basis, so that particular licenses
# aren't accepted for every possible crate as with the normal allow list
exceptions = [
    # Each entry is the crate and version constraint, and its the license
    { allow = ["OpenSSL"], name = "ring", version = "*" },
]

# Some crates don't have (easily) machine readable licensing information,
# adding a clarification entry for it allows you to manually specify the
# licensing information
[[licenses.clarify]]
# The name of the crate the clarification applies to
name = "ring"
# The optional version constraint for the crate
version = "*"
# The SPDX expression for the license requirements of the crate
expression = "MIT AND ISC AND OpenSSL"
# One or more files in the crate's source used as the "source of truth" for
# the license expression. If the files are missing, or do not contain the
# specified license text, the clarification will fail
license-files = [
    { path = "LICENSE", hash = 0xbd0eed23 },
]

[bans]
# Lint level for when multiple versions of the same crate are detected
multiple-versions = "warn"
# Lint level for when a crate version requirement is `*`
wildcards = "allow"
# The graph highlighting used when creating dotgraphs for crates
# with multiple versions
highlight = "all"
# The default lint level for `default` features, if not specified in `features`
default-features = "allow"
# The feature set to use for each crate
features = []
# List of crates that are allowed. Use with care!
allow = []
# List of crates to deny
deny = [
    # Each entry the name of a crate and a version range. If version is
    # not specified, all versions will be matched.
    #{ name = "ansi_term", version = "=0.11.0" },
    
    # Wrapper crates can optionally be specified to allow the crate when it
    # is a direct dependency of the otherwise banned crate
    #{ name = "ansi_term", version = "=0.11.0", wrappers = [] },
]

# Certain crates/versions that will be skipped when doing duplicate detection.
skip = [
    #{ name = "ansi_term", version = "=0.11.0" },
]
# Similarly to `skip` allows you to skip certain crates from being checked. Unlike `skip`,
# `skip-tree` skips the crate and all of its dependencies entirely.
skip-tree = [
    #{ name = "ansi_term", version = "=0.11.0" },
]

[advisories]
# The path where the advisory database is cloned/fetched into
db-path = "~/.cargo/advisory-db"
# The url(s) of the advisory databases to use
db-urls = ["https://github.com/rustsec/advisory-db"]
# The lint level for security vulnerabilities
vulnerability = "deny"
# The lint level for unmaintained crates
unmaintained = "warn"
# The lint level for crates that have been yanked from their source registry
yanked = "warn"
# The lint level for crates with security notices. Note that as of
# 2019-12-17 there are no security notice advisories in
# https://github.com/rustsec/advisory-db
notice = "warn"
# A list of advisory IDs to ignore. Note that ignored advisories will still
# output a note when they are encountered.
ignore = [
    #"RUSTSEC-0000-0000",
]
# Threshold for security vulnerabilities, any vulnerability with a CVSS score
# lower than this value will be ignored. Note that ignored advisories will still
# output a note when they are encountered.
# * None (default) - CVSS Score 0.0
# * Low - CVSS Score 0.1 - 3.9
# * Medium - CVSS Score 4.0 - 6.9
# * High - CVSS Score 7.0 - 8.9
# * Critical - CVSS Score 9.0 - 10.0
#severity-threshold = 

[sources]
# Lint level for what to happen when a crate from a crate registry that is
# not in the allow list is encountered
unknown-registry = "warn"
# Lint level for what to happen when a crate from a git repository that is not
# in the allow list is encountered
unknown-git = "warn"
# List of URLs for allowed crate registries. Defaults to the crates.io index
# if not specified. If it is specified but empty, no registries are allowed.
allow-registry = ["https://github.com/rust-lang/crates.io-index"]
# List of URLs for allowed Git repositories
allow-git = [] {
  "authentication": {
    "jwt_secret": "doe_sere_secre_dk43n54h23092z223"
  },
  "web": {
    "listen": "0.0.0.0",
    "port": 8081,
    "api_path": "/api",
    "cors_origins": ["*"]
  },
  "websocket": {
    "rate_limiting": {
      "enabled": true,
      "requests_per_minute": 60,
      "burst_size": 10
    }
  }
} # Genesis Node Configuration
[node]
type = "genesis"
id = "genesis-001"
name = "Atous Security Genesis Node"
version = "0.1.0"

[network]
# P2P Network configuration
bind_address = "0.0.0.0:30333"
public_address = "genesis.atous.network:30333"
max_peers = 50
discovery_enabled = true
mdns_enabled = true
bootstrap_nodes = []

# HTTP API configuration
[api]
enabled = true
bind_address = "0.0.0.0:8080"
cors_enabled = true
cors_origins = ["*"]
max_request_size = 131072  # 128KB
rate_limit_per_minute = 60

# WebSocket configuration
[websocket]
enabled = true
bind_address = "0.0.0.0:9000"
max_connections = 100

# Security configuration
[security]
# JWT for API authentication
jwt_secret = "your-secure-jwt-secret-change-in-production"
jwt_expiry_hours = 24

# Rate limiting
rate_limit_enabled = true
rate_limit_max_requests = 5
rate_limit_window_minutes = 1

# Sybil protection
sybil_protection_enabled = true
max_nodes_per_ip = 3
sybil_analysis_window_hours = 1

# Neural immune system
neural_immune_enabled = true
min_reputation_threshold = 500
min_flags_for_isolation = 3
consensus_threshold = 0.67

[storage]
data_dir = "/app/data"
blockchain_path = "/app/data/blockchain"
logs_path = "/app/logs"
max_log_size_mb = 100
log_rotation_days = 7

[consensus]
# Genesis node specific settings
is_genesis = true
genesis_timestamp = 1704067200  # 2024-01-01 00:00:00 UTC
initial_validators = ["genesis-001"]
block_time_seconds = 10
max_block_size = 1048576  # 1MB

[monitoring]
metrics_enabled = true
prometheus_endpoint = "0.0.0.0:9615"
telemetry_enabled = false
health_check_interval_seconds = 30

[logging]
level = "info"
format = "json"
file_enabled = true
console_enabled = true

# Performance tuning
[performance]
worker_threads = 4
max_blocking_threads = 8
thread_stack_size = 2097152  # 2MB
gc_threshold_mb = 256

# Development and testing
[development]
dev_mode = false
test_mode = false
mock_time = false
skip_genesis_validation = false #!/bin/bash

# Atous Network-Specific Security Tests
# Test Session ID: 9581f195-8fa1-431f-a6e4-157486aa0dc1
# Tests specific to Atous P2P network security implementations

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
PURPLE='\033[0;35m'
NC='\033[0m' # No Color

TEST_SESSION_ID="9581f195-8fa1-431f-a6e4-157486aa0dc1"
TARGET_HOST="localhost"
API_PORT="8081"
P2P_PORT="8083"

echo -e "${BLUE}=== Atous Network-Specific Security Tests ===${NC}"
echo -e "Test Session ID: ${YELLOW}${TEST_SESSION_ID}${NC}"
echo ""

# Function to log test results
log_test() {
    local test_name="$1"
    local result="$2"
    local details="$3"
    
    if [ "$result" = "PASS" ]; then
        echo -e "${GREEN}[PASS]${NC} $test_name"
    elif [ "$result" = "FAIL" ]; then
        echo -e "${RED}[FAIL]${NC} $test_name"
    elif [ "$result" = "VULN" ]; then
        echo -e "${RED}[VULNERABILITY]${NC} $test_name"
    else
        echo -e "${YELLOW}[INFO]${NC} $test_name"
    fi
    
    if [ -n "$details" ]; then
        echo "       $details"
    fi
    echo ""
}

# Test Sybil Protection Implementation
test_sybil_protection_detailed() {
    echo -e "${PURPLE}=== Advanced Sybil Protection Tests ===${NC}"
    
    # Test 1: IP-based peer limiting (based on your config: max_peers_per_ip)
    echo "Testing IP-based peer limiting..."
    
    # Simulate multiple peer connections from same IP
    blocked_count=0
    accepted_count=0
    
    for i in {1..10}; do
        # Create unique peer IDs
        peer_id="peer-${i}-${RANDOM}"
        
        # Attempt to register/connect peer
        response=$(curl -s -w "%{http_code}" -o /dev/null \
            -X POST \
            -H "Content-Type: application/json" \
            -H "X-Real-IP: 192.168.1.100" \
            -d "{\"peer_id\":\"$peer_id\",\"action\":\"connect\",\"session_id\":\"${TEST_SESSION_ID}\"}" \
            http://${TARGET_HOST}:${API_PORT}/api/flags 2>/dev/null)
        
        if [ "$response" = "429" ] || [ "$response" = "403" ]; then
            ((blocked_count++))
            log_test "Sybil IP limit test #$i" "PASS" "Peer blocked: HTTP $response"
        elif [ "$response" = "200" ] || [ "$response" = "201" ]; then
            ((accepted_count++))
        fi
        
        sleep 0.1
    done
    
    if [ $blocked_count -gt 0 ]; then
        log_test "IP-based Sybil protection" "PASS" "$blocked_count/$((blocked_count + accepted_count)) connections blocked"
    else
        log_test "IP-based Sybil protection" "VULN" "All connections accepted - no IP limiting detected"
    fi
    
    # Test 2: Churn detection (rapid connect/disconnect)
    echo "Testing churn detection..."
    
    for i in {1..20}; do
        peer_id="churn-peer-${i}"
        
        # Connect
        curl -s -X POST \
            -H "Content-Type: application/json" \
            -d "{\"peer_id\":\"$peer_id\",\"action\":\"connect\",\"session_id\":\"${TEST_SESSION_ID}\"}" \
            http://${TARGET_HOST}:${API_PORT}/api/flags > /dev/null 2>&1
        
        # Disconnect immediately
        curl -s -X POST \
            -H "Content-Type: application/json" \
            -d "{\"peer_id\":\"$peer_id\",\"action\":\"disconnect\",\"session_id\":\"${TEST_SESSION_ID}\"}" \
            http://${TARGET_HOST}:${API_PORT}/api/flags > /dev/null 2>&1
        
        sleep 0.05  # Very rapid churn
    done
    
    # Try one more connection after rapid churn
    response=$(curl -s -w "%{http_code}" -o /dev/null \
        -X POST \
        -H "Content-Type: application/json" \
        -d "{\"peer_id\":\"final-churn-test\",\"action\":\"connect\",\"session_id\":\"${TEST_SESSION_ID}\"}" \
        http://${TARGET_HOST}:${API_PORT}/api/flags 2>/dev/null)
    
    if [ "$response" = "429" ] || [ "$response" = "403" ]; then
        log_test "Churn detection" "PASS" "Rapid churn detected and blocked: HTTP $response"
    else
        log_test "Churn detection" "VULN" "Rapid churn not detected: HTTP $response"
    fi
}

# Test Eclipse Protection Implementation
test_eclipse_protection_detailed() {
    echo -e "${PURPLE}=== Advanced Eclipse Protection Tests ===${NC}"
    
    # Test subnet diversity enforcement
    echo "Testing subnet diversity enforcement..."
    
    # Based on your config: min_distinct_subnets = 5
    subnets=(
        "192.168.1"
        "192.168.1"  # Same subnet repeated
        "192.168.1"
        "192.168.1"
        "192.168.1"
        "10.0.0"     # Different subnet
        "172.16.0"   # Different subnet
    )
    
    subnet_blocked=false
    
    for i in "${!subnets[@]}"; do
        subnet="${subnets[$i]}"
        ip="${subnet}.$((i+1))"
        
        response=$(curl -s -w "%{http_code}" -o /dev/null \
            -X POST \
            -H "Content-Type: application/json" \
            -H "X-Forwarded-For: $ip" \
            -d "{\"peer_id\":\"subnet-test-$i\",\"bucket_id\":\"test-bucket\",\"action\":\"join\",\"session_id\":\"${TEST_SESSION_ID}\"}" \
            http://${TARGET_HOST}:${API_PORT}/api/flags 2>/dev/null)
        
        if [ "$response" = "429" ] || [ "$response" = "403" ]; then
            subnet_blocked=true
            log_test "Subnet diversity test #$i" "PASS" "Subnet $subnet connection blocked: HTTP $response"
        fi
        
        sleep 0.1
    done
    
    if [ "$subnet_blocked" = true ]; then
        log_test "Eclipse subnet protection" "PASS" "Subnet concentration detected and blocked"
    else
        log_test "Eclipse subnet protection" "VULN" "No subnet diversity enforcement detected"
    fi
    
    # Test bucket segregation
    echo "Testing bucket segregation..."
    
    # Try to fill multiple buckets with same subnet
    for bucket in "bucket-1" "bucket-2" "bucket-3"; do
        for peer_num in {1..3}; do
            response=$(curl -s -w "%{http_code}" -o /dev/null \
                -X POST \
                -H "Content-Type: application/json" \
                -H "X-Forwarded-For: 192.168.100.$peer_num" \
                -d "{\"peer_id\":\"bucket-test-$bucket-$peer_num\",\"bucket_id\":\"$bucket\",\"session_id\":\"${TEST_SESSION_ID}\"}" \
                http://${TARGET_HOST}:${API_PORT}/api/flags 2>/dev/null)
            
            if [ "$response" = "403" ] || [ "$response" = "429" ]; then
                log_test "Bucket protection" "PASS" "Bucket $bucket protected against same-subnet flooding"
                break
            fi
        done
    done
}

# Test P2P Network Protocol Security
test_p2p_protocol_security() {
    echo -e "${PURPLE}=== P2P Protocol Security Tests ===${NC}"
    
    # Test if P2P port accepts malformed libp2p messages
    if command -v nc &> /dev/null; then
        echo "Testing P2P port with malformed data..."
        
        # Send malformed data to P2P port
        echo "MALFORMED_P2P_DATA" | timeout 3 nc ${TARGET_HOST} ${P2P_PORT} > /tmp/p2p_test 2>&1
        
        if [ $? -eq 0 ] && [ -s /tmp/p2p_test ]; then
            log_test "P2P malformed data handling" "VULN" "P2P port accepted malformed data"
        else
            log_test "P2P malformed data handling" "PASS" "P2P port rejected malformed data"
        fi
        
        rm -f /tmp/p2p_test
    fi
    
    # Test Noise protocol implementation (if accessible)
    echo "Testing Noise protocol security..."
    
    # This would require actual libp2p client - simulate by checking if port responds to HTTP
    response=$(curl -s -w "%{http_code}" -o /dev/null --max-time 2 http://${TARGET_HOST}:${P2P_PORT}/ 2>/dev/null)
    
    if [ "$response" = "000" ] || [ -z "$response" ]; then
        log_test "Noise protocol isolation" "PASS" "P2P port doesn't respond to HTTP (properly isolated)"
    else
        log_test "P2P HTTP exposure" "VULN" "P2P port responds to HTTP: $response"
    fi
}

# Test Cryptographic Implementation
test_cryptographic_security() {
    echo -e "${PURPLE}=== Cryptographic Security Tests ===${NC}"
    
    # Test post-quantum cryptography configuration
    response=$(curl -s http://${TARGET_HOST}:${API_PORT}/api/config 2>/dev/null)
    
    if echo "$response" | grep -qi "ml-kem-768\|dilithium\|post.*quantum"; then
        log_test "Post-quantum crypto" "PASS" "Post-quantum algorithms detected in config"
    else
        log_test "Post-quantum crypto" "INFO" "Post-quantum crypto config not visible"
    fi
    
    # Test encryption algorithm support
    algorithms=("chacha20poly1305" "aes256gcm")
    
    for algo in "${algorithms[@]}"; do
        # Test if algorithm is supported (this would need actual crypto endpoint)
        response=$(curl -s -X POST \
            -H "Content-Type: application/json" \
            -d "{\"algorithm\":\"$algo\",\"test\":\"encryption_support\"}" \
            http://${TARGET_HOST}:${API_PORT}/api/crypto/test 2>/dev/null)
        
        if [ $? -eq 0 ]; then
            log_test "Encryption algorithm $algo" "INFO" "Algorithm test endpoint available"
        fi
    done
}

# Test Flag System Security
test_flag_system_security() {
    echo -e "${PURPLE}=== Flag System Security Tests ===${NC}"
    
    # Test flag validation with invalid signatures
    echo "Testing flag validation..."
    
    invalid_flag='{
        "reporter_id": "malicious-node",
        "target_node": "'${TEST_SESSION_ID}'",
        "flag_type": "MALICIOUS_BEHAVIOR",
        "evidence": "fake evidence",
        "signature": "invalid_signature_data",
        "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"
    }'
    
    response=$(curl -s -w "%{http_code}" -o /dev/null \
        -X POST \
        -H "Content-Type: application/json" \
        -d "$invalid_flag" \
        http://${TARGET_HOST}:${API_PORT}/api/flags 2>/dev/null)
    
    if [ "$response" = "400" ] || [ "$response" = "401" ] || [ "$response" = "422" ]; then
        log_test "Flag signature validation" "PASS" "Invalid signature rejected: HTTP $response"
    else
        log_test "Flag signature bypass" "VULN" "Invalid signature accepted: HTTP $response"
    fi
    
    # Test flag spam protection
    echo "Testing flag spam protection..."
    
    spam_count=0
    blocked_count=0
    
    for i in {1..20}; do
        spam_flag='{
            "reporter_id": "spam-reporter-'$i'",
            "target_node": "'${TEST_SESSION_ID}'",
            "flag_type": "SPAM_TEST",
            "evidence": "spam test #'$i'",
            "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"
        }'
        
        response=$(curl -s -w "%{http_code}" -o /dev/null \
            -X POST \
            -H "Content-Type: application/json" \
            -d "$spam_flag" \
            http://${TARGET_HOST}:${API_PORT}/api/flags 2>/dev/null)
        
        if [ "$response" = "429" ] || [ "$response" = "403" ]; then
            ((blocked_count++))
        else
            ((spam_count++))
        fi
        
        sleep 0.1
    done
    
    if [ $blocked_count -gt 0 ]; then
        log_test "Flag spam protection" "PASS" "$blocked_count/20 spam flags blocked"
    else
        log_test "Flag spam vulnerability" "VULN" "All spam flags accepted"
    fi
}

# Main execution
main() {
    echo -e "${BLUE}Starting Atous network-specific security tests...${NC}\n"
    
    # Check if target is reachable
    if ! curl -s --max-time 5 http://${TARGET_HOST}:${API_PORT}/api/metrics/energy > /dev/null 2>&1; then
        echo -e "${RED}Error: Target ${TARGET_HOST}:${API_PORT} is not reachable${NC}"
        echo "Please ensure the Atous server is running."
        exit 1
    fi
    
    test_sybil_protection_detailed
    test_eclipse_protection_detailed
    test_p2p_protocol_security
    test_cryptographic_security
    test_flag_system_security
    
    echo -e "${BLUE}=== Network-Specific Security Testing Complete ===${NC}"
    echo -e "Test Session ID: ${YELLOW}${TEST_SESSION_ID}${NC}"
    echo ""
    echo -e "${YELLOW}Recommendations:${NC}"
    echo "1. Review any VULNERABILITY findings immediately"
    echo "2. Verify Sybil protection configuration in config.json"
    echo "3. Check Eclipse protection subnet diversity settings"
    echo "4. Ensure post-quantum cryptography is properly enabled"
    echo "5. Validate flag system signature verification"
    echo ""
    echo -e "${GREEN}Next steps:${NC}"
    echo "- Run the general penetration test suite: ./penetration_test_suite.sh"
    echo "- Monitor logs for security events during testing"
    echo "- Update security configurations based on findings"
}

# Execute main function
main "$@" #!/bin/bash

# Atous Network Security Penetration Testing Suite
# Test Session ID: 9581f195-8fa1-431f-a6e4-157486aa0dc1

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
PURPLE='\033[0;35m'
NC='\033[0m' # No Color

# Test configuration
TEST_SESSION_ID="9581f195-8fa1-431f-a6e4-157486aa0dc1"
TARGET_HOST="localhost"
API_PORT="8081"
WS_PORT="8082"
P2P_PORT="8083"
METRICS_PORT="9090"

echo -e "${BLUE}=== Atous Network Security Penetration Testing Suite ===${NC}"
echo -e "Test Session ID: ${YELLOW}${TEST_SESSION_ID}${NC}"
echo -e "Target: ${TARGET_HOST}:${API_PORT}"
echo ""

# Function to log test results
log_test() {
    local test_name="$1"
    local result="$2"
    local details="$3"
    
    if [ "$result" = "PASS" ]; then
        echo -e "${GREEN}[PASS]${NC} $test_name"
    elif [ "$result" = "FAIL" ]; then
        echo -e "${RED}[FAIL]${NC} $test_name"
    elif [ "$result" = "VULN" ]; then
        echo -e "${RED}[VULNERABILITY]${NC} $test_name"
    else
        echo -e "${YELLOW}[INFO]${NC} $test_name"
    fi
    
    if [ -n "$details" ]; then
        echo "       $details"
    fi
    echo ""
}

# Test 1: Rate Limiting Protection
test_rate_limiting() {
    echo -e "${PURPLE}=== Test 1: Rate Limiting Protection ===${NC}"
    
    # Test normal request rate
    response=$(curl -s -w "%{http_code}" -o /dev/null http://${TARGET_HOST}:${API_PORT}/api/metrics/energy)
    if [ "$response" = "200" ]; then
        log_test "Normal API request" "PASS" "HTTP $response"
    else
        log_test "Normal API request" "FAIL" "HTTP $response"
    fi
    
    # Test rapid requests (potential DDoS)
    echo "Testing rapid requests (100 requests in 5 seconds)..."
    success_count=0
    rate_limited_count=0
    
    for i in {1..100}; do
        response=$(curl -s -w "%{http_code}" -o /dev/null --max-time 1 http://${TARGET_HOST}:${API_PORT}/api/metrics/energy 2>/dev/null)
        if [ "$response" = "200" ]; then
            ((success_count++))
        elif [ "$response" = "429" ]; then
            ((rate_limited_count++))
        fi
        sleep 0.05
    done
    
    if [ $rate_limited_count -gt 0 ]; then
        log_test "Rate limiting active" "PASS" "Rate limited: $rate_limited_count/100 requests"
    else
        log_test "Rate limiting bypass" "VULN" "All requests succeeded - rate limiting may be disabled"
    fi
}

# Test 2: Authentication Bypass
test_authentication() {
    echo -e "${PURPLE}=== Test 2: Authentication Bypass ===${NC}"
    
    # Test unauthenticated access to protected endpoints
    endpoints=(
        "/api/flags"
        "/api/node/${TEST_SESSION_ID}/status"
        "/api/network/status"
        "/metrics"
    )
    
    for endpoint in "${endpoints[@]}"; do
        response=$(curl -s -w "%{http_code}" -o /dev/null http://${TARGET_HOST}:${API_PORT}${endpoint})
        
        if [ "$response" = "401" ] || [ "$response" = "403" ]; then
            log_test "Auth required for $endpoint" "PASS" "HTTP $response"
        elif [ "$response" = "200" ]; then
            log_test "Unauthenticated access to $endpoint" "VULN" "HTTP $response - No authentication required"
        else
            log_test "Endpoint $endpoint" "INFO" "HTTP $response"
        fi
    done
    
    # Test JWT manipulation
    fake_jwt="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkF0dGFja2VyIiwiaWF0IjoxNTE2MjM5MDIyfQ.invalid_signature"
    
    response=$(curl -s -w "%{http_code}" -o /dev/null -H "Authorization: Bearer $fake_jwt" http://${TARGET_HOST}:${API_PORT}/api/flags)
    
    if [ "$response" = "401" ] || [ "$response" = "403" ]; then
        log_test "JWT validation" "PASS" "HTTP $response - Invalid JWT rejected"
    else
        log_test "JWT bypass" "VULN" "HTTP $response - Invalid JWT accepted"
    fi
}

# Test 3: Input Validation & Injection
test_input_validation() {
    echo -e "${PURPLE}=== Test 3: Input Validation & Injection ===${NC}"
    
    # SQL Injection attempts
    sql_payloads=(
        "'; DROP TABLE flags; --"
        "' OR '1'='1"
        "1' UNION SELECT * FROM users --"
    )
    
    for payload in "${sql_payloads[@]}"; do
        response=$(curl -s -w "%{http_code}" -o /dev/null -G -d "node_id=$payload" http://${TARGET_HOST}:${API_PORT}/api/node/status)
        
        if [ "$response" = "400" ] || [ "$response" = "422" ]; then
            log_test "SQL injection protection" "PASS" "Payload blocked: $payload"
        elif [ "$response" = "500" ]; then
            log_test "Potential SQL injection" "VULN" "Server error with payload: $payload"
        fi
    done
    
    # XSS attempts
    xss_payloads=(
        "<script>alert('xss')</script>"
        "javascript:alert('xss')"
        "<img src=x onerror=alert('xss')>"
    )
    
    for payload in "${xss_payloads[@]}"; do
        response=$(curl -s -X POST -H "Content-Type: application/json" -d "{\"node_id\":\"$payload\"}" http://${TARGET_HOST}:${API_PORT}/api/flags)
        
        if [ "$(echo $response | grep -c '<script>')" -eq 0 ]; then
            log_test "XSS protection" "PASS" "Payload sanitized: $payload"
        else
            log_test "Potential XSS" "VULN" "Payload reflected: $payload"
        fi
    done
}

# Test 4: Network Protocol Security
test_network_security() {
    echo -e "${PURPLE}=== Test 4: Network Protocol Security ===${NC}"
    
    # Test P2P port accessibility
    if nc -z ${TARGET_HOST} ${P2P_PORT} 2>/dev/null; then
        log_test "P2P port accessible" "INFO" "Port ${P2P_PORT} is open"
        
        # Test if P2P port accepts HTTP requests (should not)
        response=$(curl -s -w "%{http_code}" -o /dev/null --max-time 2 http://${TARGET_HOST}:${P2P_PORT}/ 2>/dev/null)
        if [ "$response" = "000" ] || [ -z "$response" ]; then
            log_test "P2P port security" "PASS" "Port does not respond to HTTP"
        else
            log_test "P2P HTTP response" "VULN" "P2P port responds to HTTP: $response"
        fi
    else
        log_test "P2P port" "INFO" "Port ${P2P_PORT} is closed/filtered"
    fi
    
    # Test WebSocket security
    if command -v websocat &> /dev/null; then
        echo "Testing WebSocket connection..."
        timeout 3 websocat ws://${TARGET_HOST}:${WS_PORT}/ws --text --oneshot <<< "test" > /tmp/ws_test 2>&1
        
        if grep -q "WebSocket connection" /tmp/ws_test; then
            log_test "WebSocket connection" "INFO" "WebSocket accepts connections"
        else
            log_test "WebSocket security" "PASS" "WebSocket connection restricted"
        fi
        rm -f /tmp/ws_test
    else
        log_test "WebSocket test" "INFO" "websocat not available - skipping"
    fi
}

# Test 5: DoS Resistance
test_dos_resistance() {
    echo -e "${PURPLE}=== Test 5: DoS Resistance ===${NC}"
    
    # Test connection flooding
    echo "Testing connection flooding..."
    connections=0
    for i in {1..50}; do
        if curl -s --max-time 1 http://${TARGET_HOST}:${API_PORT}/api/metrics/energy > /dev/null 2>&1; then
            ((connections++))
        fi &
    done
    
    wait
    
    if [ $connections -lt 50 ]; then
        log_test "Connection limiting" "PASS" "Only $connections/50 connections succeeded"
    else
        log_test "Connection flooding" "VULN" "All $connections connections succeeded"
    fi
    
    # Test memory exhaustion via large payloads
    large_payload=$(python3 -c "print('A' * 1000000)")  # 1MB payload
    response=$(curl -s -w "%{http_code}" -o /dev/null --max-time 5 -X POST -d "$large_payload" http://${TARGET_HOST}:${API_PORT}/api/flags 2>/dev/null)
    
    if [ "$response" = "413" ] || [ "$response" = "400" ]; then
        log_test "Large payload protection" "PASS" "HTTP $response"
    elif [ "$response" = "000" ]; then
        log_test "Large payload handling" "PASS" "Connection timeout/reset"
    else
        log_test "Large payload acceptance" "VULN" "HTTP $response - Large payload accepted"
    fi
}

# Test 6: Information Disclosure
test_information_disclosure() {
    echo -e "${PURPLE}=== Test 6: Information Disclosure ===${NC}"
    
    # Test for exposed configuration
    sensitive_endpoints=(
        "/config"
        "/config.json"
        "/api/config"
        "/.env"
        "/debug"
        "/api/debug"
        "/status"
        "/health"
    )
    
    for endpoint in "${sensitive_endpoints[@]}"; do
        response=$(curl -s -w "%{http_code}" -o /tmp/response http://${TARGET_HOST}:${API_PORT}${endpoint} 2>/dev/null)
        
        if [ "$response" = "200" ]; then
            if grep -qi "password\|secret\|key\|token" /tmp/response; then
                log_test "Information disclosure" "VULN" "$endpoint exposes sensitive data"
            else
                log_test "Endpoint accessibility" "INFO" "$endpoint accessible but no sensitive data visible"
            fi
        fi
    done
    
    rm -f /tmp/response
    
    # Test error message disclosure
    response=$(curl -s http://${TARGET_HOST}:${API_PORT}/api/nonexistent/endpoint)
    if echo "$response" | grep -qi "stack trace\|error.*line\|debug\|exception"; then
        log_test "Error message disclosure" "VULN" "Detailed error messages exposed"
    else
        log_test "Error handling" "PASS" "Generic error messages"
    fi
}

# Test 7: Sybil Attack Simulation
test_sybil_attack() {
    echo -e "${PURPLE}=== Test 7: Sybil Attack Simulation ===${NC}"
    
    # Simulate multiple connections from same IP
    echo "Simulating Sybil attack (multiple node IDs from same IP)..."
    
    sybil_nodes=()
    for i in {1..10}; do
        node_id=$(uuidgen 2>/dev/null || echo "node-$i-$RANDOM")
        sybil_nodes+=($node_id)
        
        response=$(curl -s -w "%{http_code}" -o /dev/null -X POST -H "Content-Type: application/json" \
            -d "{\"node_id\":\"$node_id\",\"session_id\":\"${TEST_SESSION_ID}\"}" \
            http://${TARGET_HOST}:${API_PORT}/api/flags 2>/dev/null)
        
        if [ "$response" = "429" ] || [ "$response" = "403" ]; then
            log_test "Sybil protection active" "PASS" "Connection $i blocked: HTTP $response"
            break
        fi
    done
    
    if [ ${#sybil_nodes[@]} -eq 10 ]; then
        log_test "Sybil attack successful" "VULN" "All 10 fake nodes accepted"
    fi
}

# Test 8: Eclipse Attack Simulation
test_eclipse_attack() {
    echo -e "${PURPLE}=== Test 8: Eclipse Attack Simulation ===${NC}"
    
    # Test subnet diversity requirements
    subnets=("192.168.1" "192.168.2" "10.0.0" "172.16.0")
    
    for subnet in "${subnets[@]}"; do
        # Simulate connections from multiple IPs in same subnet
        for i in {1..5}; do
            # This is a simulation - in real test you'd need to actually connect from different IPs
            response=$(curl -s -w "%{http_code}" -o /dev/null \
                -H "X-Forwarded-For: ${subnet}.$i" \
                -H "X-Real-IP: ${subnet}.$i" \
                http://${TARGET_HOST}:${API_PORT}/api/metrics/energy 2>/dev/null)
            
            if [ "$response" = "403" ] || [ "$response" = "429" ]; then
                log_test "Eclipse protection" "PASS" "Subnet $subnet connections limited"
                break
            fi
        done
    done
}

# Main execution
main() {
    echo -e "${BLUE}Starting comprehensive penetration testing...${NC}\n"
    
    # Check if target is reachable
    if ! curl -s --max-time 5 http://${TARGET_HOST}:${API_PORT}/api/metrics/energy > /dev/null; then
        echo -e "${RED}Error: Target ${TARGET_HOST}:${API_PORT} is not reachable${NC}"
        echo "Please ensure the Atous server is running."
        exit 1
    fi
    
    test_rate_limiting
    test_authentication
    test_input_validation
    test_network_security
    test_dos_resistance
    test_information_disclosure
    test_sybil_attack
    test_eclipse_attack
    
    echo -e "${BLUE}=== Penetration Testing Complete ===${NC}"
    echo -e "Test Session ID: ${YELLOW}${TEST_SESSION_ID}${NC}"
    echo ""
    echo -e "${YELLOW}Summary:${NC}"
    echo "- Review all VULNERABILITY findings immediately"
    echo "- INFO findings should be evaluated for security implications"
    echo "- PASS results indicate security controls are working"
    echo ""
    echo -e "${RED}‚ö†Ô∏è  This tool is for authorized testing only${NC}"
    echo -e "${RED}‚ö†Ô∏è  Do not use against systems you don't own${NC}"
}

# Execute main function
main "$@" global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'atous'
    static_configs:
      - targets: ['atous:9090']
    
  - job_name: 'bootstrap'
    static_configs:
      - targets: ['bootstrap:9090']

  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']   Compiling atous-security-fixes v0.1.0 (/home/atous-security/Documentos/projects/rust)
    Finished `dev` profile [unoptimized + debuginfo] target(s) in 12.06s
     Running `target/debug/atous-security-fixes`
[2025-06-02T20:01:11Z INFO  actix_server::builder] starting 2 workers
[2025-06-02T20:01:11Z INFO  atous_security_fixes] üöÄ Atous Security Server running at http://127.0.0.1:8081
[2025-06-02T20:01:11Z INFO  atous_security_fixes] üîí API endpoints available at http://127.0.0.1:8081/api
[2025-06-02T20:01:11Z INFO  atous_security_fixes] üìä Metrics endpoint available at http://127.0.0.1:8081/api/metrics (AUTH REQUIRED)
[2025-06-02T20:01:11Z INFO  atous_security_fixes] üõ°Ô∏è ENHANCED SECURITY FIXES APPLIED:
[2025-06-02T20:01:11Z INFO  atous_security_fixes]   ‚úÖ Authentication middleware runs BEFORE rate limiting
[2025-06-02T20:01:11Z INFO  atous_security_fixes]   ‚úÖ Payload size LIMITED to 128KB (reduced from 256KB)
[2025-06-02T20:01:11Z INFO  atous_security_fixes]   ‚úÖ JSON payload LIMITED to 128KB
[2025-06-02T20:01:11Z INFO  atous_security_fixes]   ‚úÖ Form data LIMITED to 64KB
[2025-06-02T20:01:11Z INFO  atous_security_fixes]   ‚úÖ Flag signature validation enabled
[2025-06-02T20:01:11Z INFO  atous_security_fixes]   ‚úÖ Rate limiting: 5 req/min, 2 concurrent (REDUCED)
[2025-06-02T20:01:11Z INFO  atous_security_fixes]   ‚úÖ Sybil protection: max 1 node per IP (STRICTER)
[2025-06-02T20:01:11Z INFO  atous_security_fixes]   ‚úÖ Metrics endpoint protected by authentication
[2025-06-02T20:01:11Z INFO  atous_security_fixes]   ‚úÖ CORS restricted to specific origins
[2025-06-02T20:01:11Z INFO  atous_security_fixes]   ‚úÖ Connection limits: 100 max, 10/sec rate
[2025-06-02T20:01:11Z INFO  atous_security_fixes]   ‚úÖ Request timeout: 10 seconds
[2025-06-02T20:01:11Z INFO  atous_security_fixes]   üîê VULNERABILITY FIXES: Large payload protection enhanced
[2025-06-02T20:01:11Z INFO  actix_server::server] Actix runtime found; starting in Actix runtime
[2025-06-02T20:01:11Z INFO  actix_server::server] starting service: "actix-web-service-127.0.0.1:8081", workers: 2, listening on: 127.0.0.1:8081
[2025-06-02T20:02:14Z INFO  actix_web::middleware::logger] 127.0.0.1 "GET /health HTTP/1.1" 404 0 "-" "curl/8.5.0" 0.000205
[2025-06-02T20:02:14Z INFO  actix_web::middleware::logger] 127.0.0.1 "GET /health HTTP/1.1" 404 0 "-" "curl/8.5.0" 0.000085
[2025-06-02T20:02:14Z INFO  actix_web::middleware::logger] 127.0.0.1 "GET /health HTTP/1.1" 404 0 "-" "curl/8.5.0" 0.000075
[2025-06-02T20:02:14Z INFO  actix_web::middleware::logger] 127.0.0.1 "GET /health HTTP/1.1" 404 0 "-" "curl/8.5.0" 0.000125
[2025-06-02T20:02:14Z INFO  actix_web::middleware::logger] 127.0.0.1 "GET /health HTTP/1.1" 404 0 "-" "curl/8.5.0" 0.000113
[2025-06-02T20:02:14Z INFO  actix_web::middleware::logger] 127.0.0.1 "GET /health HTTP/1.1" 404 0 "-" "curl/8.5.0" 0.000086
[2025-06-02T20:02:14Z INFO  actix_web::middleware::logger] 127.0.0.1 "GET /health HTTP/1.1" 404 0 "-" "curl/8.5.0" 0.000069
[2025-06-02T20:02:19Z INFO  actix_web::middleware::logger] 127.0.0.1 "GET / HTTP/1.1" 404 0 "-" "curl/8.5.0" 0.000068
[2025-06-02T20:02:19Z WARN  atous_security_fixes::middleware::rate_limit] Rate limit violation from 127.0.0.1:curl/8.5.0: Rate limit exceeded: 5 requests per minute (max: 5)
[2025-06-02T20:02:19Z INFO  actix_web::middleware::logger] 127.0.0.1 "GET / HTTP/1.1" 404 0 "-" "curl/8.5.0" 0.000072
[2025-06-02T20:02:19Z WARN  atous_security_fixes::middleware::rate_limit] Rate limit violation from 127.0.0.1:curl/8.5.0: Rate limit exceeded: 5 requests per minute (max: 5)
[2025-06-02T20:02:19Z WARN  atous_security_fixes::middleware::rate_limit] Rate limit violation from 127.0.0.1:curl/8.5.0: Rate limit exceeded: 5 requests per minute (max: 5)
[2025-06-02T20:02:19Z WARN  atous_security_fixes::middleware::rate_limit] Rate limit violation from 127.0.0.1:curl/8.5.0: Rate limit exceeded: 5 requests per minute (max: 5)
[2025-06-02T20:02:19Z WARN  atous_security_fixes::middleware::rate_limit] Rate limit violation from 127.0.0.1:curl/8.5.0: Rate limit exceeded: 5 requests per minute (max: 5)
[2025-06-02T20:23:11Z INFO  actix_server::server] SIGTERM received; starting graceful shutdown
[2025-06-02T20:23:11Z INFO  actix_server::worker] shutting down idle worker
[2025-06-02T20:23:11Z INFO  actix_server::worker] shutting down idle worker
[2025-06-02T20:23:11Z INFO  actix_server::accept] accept thread stopped