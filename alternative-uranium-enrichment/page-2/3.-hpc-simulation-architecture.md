# 3. HPC Simulation Architecture

#### 3. HPC Simulation Architecture

The _Prometheus Liberatus_ framework is implemented as a modular, scalable, and portable high-performance computing (HPC) system. Each phase of the enrichment pipeline—Bio-Mining, Plasma Conversion, Laser Enrichment, and Predictive Control—is treated as an independent simulation module with its own computational requirements and runtime behavior. These modules are integrated using a message-passing architecture that enables them to operate concurrently, while sharing relevant data in real time.

This architectural choice allows the system to scale from a single workstation with multiple threads to a distributed HPC cluster with hundreds of compute nodes. It also ensures that each phase can be developed, optimized, and benchmarked independently, while remaining interoperable within the full pipeline.

**3.1 Software Stack**

The software infrastructure is built from widely adopted scientific computing tools, optimized for portability across different hardware environments. It includes:

* **CUDA (C++)** for GPU-accelerated simulation of microbial and plasma dynamics;
* **OpenMP** for parallel threading in the plasma chemistry and fluid flow models;
* **MPI (Message Passing Interface)** for coordination across modules and compute nodes;
* **PyTorch** for defining, training, and running Graph Neural Networks (GNNs) in the AI control system;
* **Python (SciPy, mpi4py)** for orchestration, diagnostics, and inter-module communication.

All components are containerized using Docker and deployed via lightweight orchestration (e.g., Docker Swarm or SLURM-based job scheduling) to maintain reproducibility and performance consistency.

**3.2 Parallelization Strategy**

Each subsystem within the simulation is parallelized according to its computational characteristics:

* The **Bio-Mining phase** relies on **CUDA kernels** to model the behavior of millions of individual bacteria and their interactions with the ore matrix. These kernels simulate biological diffusion, reaction kinetics, and swarm dynamics in three dimensions.
* The **Plasma Conversion phase** uses **OpenMP threads** to model non-thermal plasma chemistry. Here, parallelism arises from independently computing the evolution of reaction zones within the reactor chamber, enabling real-time feedback on energy consumption and product yield.
* The **CRISLA Laser Enrichment phase** is distributed across **multiple MPI ranks**, each representing a stage in the enrichment cascade. These ranks pass UF₆ gas stream data forward and backward through the cascade, updating local isotopic concentrations and energy profiles in a counter-current arrangement.
* At the system level, a centralized **AI Control Module** aggregates data from all subsystems and computes optimal control parameters. This module runs a GNN model on dedicated GPU nodes to maintain real-time situational awareness of the entire simulation pipeline.

**3.3 Dataflow Overview**

The simulation architecture can be visualized as follows:

```mermaid

graph LR
  subgraph HPC_Cluster_MPI
    A[Bio-Mining Sim CUDA Kernels] --> D
    B[Plasma Sim OpenMP Threads] --> D
    C[CRISLA Cascade MPI Ranks] --> D
  end

  D[Data Aggregation] --> E[AI Control System GNN on GPU]
  E --> F[Optimized Parameters]
  F --> A
  F --> B
  F --> C
```

This feedback loop creates an adaptive system where simulation parameters (e.g., bacterial growth rate, reactor power, laser intensity) are continuously tuned by the AI to maintain optimal thermodynamic efficiency, minimize waste, and ensure safety boundaries are never exceeded.

The entire framework is designed to operate as a digital twin: not only simulating the process in high detail, but also learning from its own behavior, allowing it to improve performance over time and respond dynamically to changing inputs or constraints.

